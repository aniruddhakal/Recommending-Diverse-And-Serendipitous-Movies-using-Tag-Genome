{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class DataLoaderPreprocessor:\n",
    "\n",
    "    def __init__(self, base_dir='../../datasets/Movielens/', ml20m='ml-20m/', serendipity2018='serendipity-sac2018/'):\n",
    "        self.ratings_df = None\n",
    "        self.genome_scores_df = None\n",
    "        self.movies_df = None\n",
    "\n",
    "        self.movie_genre_binary_terms_df = None\n",
    "        self.movies_lemmatized_genome_term_vector_df = None\n",
    "        self.user_int_genre_terms_df = None\n",
    "        self.user_genre_binary_term_vector_df = None\n",
    "        self.user_lemmatized_genome_terms_df = None\n",
    "        self.user_full_genome_terms_df = None\n",
    "\n",
    "        self.base_dir = base_dir\n",
    "\n",
    "        # dataset_dir\n",
    "        self.ml20m = self.base_dir + ml20m\n",
    "        self.serendipity2018 = base_dir + serendipity2018\n",
    "        self.answers = serendipity2018 + 'answers.csv'\n",
    "\n",
    "        self.data_output_dir = 'output/'\n",
    "\n",
    "        self.dataset_files = {\n",
    "            'ml20m': {\n",
    "                'genome_scores': 'genome-scores.csv',\n",
    "                'movies': 'movies.csv',\n",
    "                'ratings': 'ratings.csv',\n",
    "\n",
    "                'movie_genre_binary_terms': 'movie_genre_binary_term_vector_df_bz2',\n",
    "                'user_int_genre_terms': 'user_int_terms_df_bz2',\n",
    "                'user_genre_binary_terms': 'user_genre_binary_terms_df_bz2',\n",
    "                'user_lemmatized_genome_terms': 'user_lemmatized_genome_terms_df_gzip',\n",
    "                'user_full_genome_terms': 'user_full_genome_terms_df_gzip',\n",
    "                'movies_genome_term_vector': 'movies_lemmatized_genome_vector_df_bz2'\n",
    "            },\n",
    "            'serendipity2018': {\n",
    "                'genome_scores': 'tag_genome.csv',\n",
    "                'movies': 'movies.csv',\n",
    "                'ratings': 'training.csv',\n",
    "                'answers': 'answers.csv'\n",
    "            }\n",
    "        }\n",
    "\n",
    "        self.all_movie_ids = None\n",
    "\n",
    "    def init_dataset(self, dataset):\n",
    "        dataset_dir = None\n",
    "\n",
    "        if dataset is 'serendipity2018':\n",
    "            dataset_dir = self.base_dir + self.serendipity2018\n",
    "        elif dataset is 'ml20m':\n",
    "            dataset_dir = self.base_dir + self.ml20m\n",
    "\n",
    "        return dataset_dir\n",
    "\n",
    "    def init_file_names(self, dataset):\n",
    "        dataset_dir = self.init_dataset(dataset)\n",
    "\n",
    "        genome_scores = dataset_dir + self.dataset_files[dataset]['genome_scores']\n",
    "        movies = dataset_dir + self.dataset_files[dataset]['movies']\n",
    "        ratings = dataset_dir + self.dataset_files[dataset]['ratings']\n",
    "\n",
    "        return genome_scores, movies, ratings\n",
    "\n",
    "    def init_user_data_file_names(self, dataset):\n",
    "        dataset_dir = self.init_dataset(dataset)\n",
    "\n",
    "        movie_genre_binary_terms = dataset_dir + self.data_output_dir + self.dataset_files[dataset][\n",
    "            'movie_genre_binary_terms']\n",
    "        user_int_genre_terms = dataset_dir + self.data_output_dir + self.dataset_files[dataset]['user_int_genre_terms']\n",
    "        user_genre_binary_terms = dataset_dir + self.data_output_dir + self.dataset_files[dataset][\n",
    "            'user_genre_binary_terms']\n",
    "\n",
    "        user_lemmatized_genome_terms = dataset_dir + self.data_output_dir + self.dataset_files[dataset][\n",
    "            'user_lemmatized_genome_terms']\n",
    "        user_full_genome_terms = dataset_dir + self.data_output_dir + self.dataset_files[dataset][\n",
    "            'user_full_genome_terms']\n",
    "        movies_genome_term_vector = dataset_dir + self.data_output_dir + self.dataset_files[dataset][\n",
    "            'movies_genome_term_vector']\n",
    "\n",
    "        return movie_genre_binary_terms, movies_genome_term_vector, user_int_genre_terms, user_genre_binary_terms, user_lemmatized_genome_terms, user_full_genome_terms\n",
    "\n",
    "    def load_and_preprocess_data(self, dataset):\n",
    "        print(\"\\nLoading data: movies, ratings, genome-scores...\")\n",
    "        genome_scores, movies, ratings = self.init_file_names(dataset)\n",
    "\n",
    "        # load all movies in df,\n",
    "        self.movies_df = pd.read_csv(movies)\n",
    "\n",
    "        # load tag-genome scores df\n",
    "        self.genome_scores_df = pd.read_csv(genome_scores)\n",
    "        self.genome_scores_df.columns = ['movieId', 'tagId', 'relevance']\n",
    "        self.genome_scores_df = self.genome_scores_df.pivot(index='movieId', columns='tagId', values='relevance')\n",
    "\n",
    "        # load all ratings\n",
    "        self.ratings_df = pd.read_csv(ratings)\n",
    "\n",
    "        print(\"Preprocessing data: movies, ratings, genome-scores...\")\n",
    "\n",
    "        # filter movies only under tag-genome df\n",
    "        movies_with_tag_genome = self.genome_scores_df.index.values\n",
    "\n",
    "        # filter-out movies with (no genres listed)\n",
    "        no_genre_movies = self.movies_df[self.movies_df['genres'] == '(no genres listed)']['movieId'].unique()\n",
    "\n",
    "        self.all_movie_ids = np.setdiff1d(movies_with_tag_genome, no_genre_movies)\n",
    "\n",
    "        # store final list of movie ID's\n",
    "        # udpate genome_scores_df, ratings_df and movies_df to only keep updated movie ID's\n",
    "        self.ratings_df = self.ratings_df[self.ratings_df['movieId'].isin(self.all_movie_ids)]\n",
    "        # self.genome_scores_df = self.genome_scores_df[self.genome_scores_df['movieId'].isin(self.all_movie_ids)]\n",
    "        self.genome_scores_df = self.genome_scores_df.loc[self.all_movie_ids, :]\n",
    "        self.movies_df = self.movies_df[self.movies_df['movieId'].isin(self.all_movie_ids)]\n",
    "\n",
    "        return self.ratings_df, self.genome_scores_df, self.movies_df\n",
    "\n",
    "    def load_and_process_user_data(self, dataset):\n",
    "        print(\"\\nLoading generated data: genre, genome-lemmatized, genome-full term vectors for users and movies...\")\n",
    "\n",
    "        if self.all_movie_ids is None:\n",
    "            self.load_and_preprocess_data(dataset)\n",
    "\n",
    "        movie_genre_binary_terms, movies_genome_term_vector, user_int_genre_terms, user_genre_binary_terms, user_lemmatized_genome_terms, user_full_genome_terms \\\n",
    "            = self.init_user_data_file_names(dataset)\n",
    "        # TODO load\n",
    "\n",
    "        print(\n",
    "            \"Preprocessing generated data: genre, genome-lemmatized, genome-full term vectors for users and movies...\")\n",
    "\n",
    "        self.movie_genre_binary_terms_df = pd.read_pickle(movie_genre_binary_terms, compression='bz2')\n",
    "        self.user_int_genre_terms_df = pd.read_pickle(user_int_genre_terms, compression='bz2')\n",
    "        self.user_lemmatized_genome_terms_df = pd.read_pickle(user_lemmatized_genome_terms, compression='gzip')\n",
    "        self.user_full_genome_terms_df = pd.read_pickle(user_full_genome_terms, compression='gzip')\n",
    "        self.movies_lemmatized_genome_term_vector_df = pd.read_pickle(movies_genome_term_vector, compression='bz2')\n",
    "        self.user_genre_binary_term_vector_df = pd.read_pickle(user_genre_binary_terms, compression='bz2')\n",
    "\n",
    "        # filter movies\n",
    "        self.movies_lemmatized_genome_term_vector_df = self.movies_lemmatized_genome_term_vector_df.loc[\n",
    "                                                       self.all_movie_ids, :]\n",
    "        self.user_full_genome_terms_df = self.user_full_genome_terms_df.loc[self.all_movie_ids, :]\n",
    "        self.movie_genre_binary_terms_df = self.movie_genre_binary_terms_df.loc[self.all_movie_ids, :]\n",
    "        \n",
    "        return self.movie_genre_binary_terms_df, self.movies_lemmatized_genome_term_vector_df, self.user_int_genre_terms_df, self.user_genre_binary_term_vector_df, self.user_lemmatized_genome_terms_df, self.user_full_genome_terms_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import pairwise_distances, silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "#import DataLoaderPreprocessor\n",
    "from time import time\n",
    "\n",
    "data_base_dir = '../../datasets/Movielens/'\n",
    "data_dir2 = data_base_dir + 'Movielens Latest/ml-latest/'\n",
    "data_dir = data_base_dir + 'ml-20m/'\n",
    "data_dir3 = data_base_dir + 'serendipity-sac2018/'\n",
    "answers = data_dir3 + 'answers.csv'\n",
    "\n",
    "data_output_dir = data_base_dir + 'output/'\n",
    "\n",
    "genome_scores = data_dir + 'genome-scores.csv'\n",
    "genome_tags = data_dir + 'genome-tags.csv'\n",
    "movies = data_dir + 'movies.csv'\n",
    "ratings = data_dir + 'ratings.csv'\n",
    "tags = data_dir + 'tags.csv'\n",
    "genres = data_dir + 'u.genre'\n",
    "\n",
    "user_unstemmed_genome_vector = data_dir + 'user_unstemmed_genome_terms_df_gzip'\n",
    "user_stemmed_genome_vector = data_dir + 'user_stemmed_genome_terms_df_gzip'\n",
    "\n",
    "\n",
    "class BaselineRecommender_VectorType:\n",
    "    # user binary terms, movie binary terms\n",
    "    GENRE_BINARY = 1\n",
    "\n",
    "    # user integer terms, movie binary terms\n",
    "    GENRE_INTEGER = 2\n",
    "\n",
    "    # user lemmatized terms, movie lemmatized terms\n",
    "    GENOME_LEMMATIZED = 3\n",
    "\n",
    "    # user full genome terms, movie full genome terms\n",
    "    GENOME_FULL = 4\n",
    "\n",
    "\n",
    "class ContentBased_Baseline_Recommender:\n",
    "    # TODO recommend using genre binary term vector\n",
    "    # TODO recommend using genre integer/float normalized term vector\n",
    "    # TODO recommend using random K movie selection which are not amongst users watched list\n",
    "    # TODO recommend using tag-genome term vector\n",
    "    # TODO recommend using lemmatized tag-genome term vector\n",
    "\n",
    "    def __init__(self, dataset='ml20m', movie_genre_binary_terms_df=None, movies_lemmatized_genome_term_vector_df=None,\n",
    "                 user_int_genre_terms_df=None, user_genre_binary_term_vector_df=None,\n",
    "                 user_lemmatized_genome_terms_df=None, user_full_genome_terms_df=None, ratings_df=None,\n",
    "                 genome_scores_df=None, movies_df=None):\n",
    "        self.dataset = dataset\n",
    "\n",
    "        self.movies_genre_binary_term_vector_df = movie_genre_binary_terms_df\n",
    "        self.movies_lemmatized_genome_vector_df = movies_lemmatized_genome_term_vector_df\n",
    "        self.movies_full_genome_vector_df = genome_scores_df\n",
    "\n",
    "        self.user_int_genre_terms_df = user_int_genre_terms_df\n",
    "        self.user_genre_binary_term_vector_df = user_genre_binary_term_vector_df\n",
    "\n",
    "        self.user_full_genome_terms_df = user_full_genome_terms_df\n",
    "        self.user_lemmatized_genome_terms_df = user_lemmatized_genome_terms_df\n",
    "\n",
    "        self.ratings_df = ratings_df\n",
    "        self.movies_df = movies_df\n",
    "        self.movie_average_ratings_df = None\n",
    "\n",
    "        if self.ratings_df is not None:\n",
    "            self.movie_average_ratings_df = self.ratings_df.loc[:, ['movieId', 'rating']].groupby('movieId').mean()\n",
    "\n",
    "        # ml-20m setup\n",
    "        # load all movies in df,\n",
    "        # load tag-genome scores df\n",
    "        # filter movies only under tag-genome df\n",
    "        # filter-out movies with (no genres listed)\n",
    "        # store final list of movie ID's\n",
    "        # udpate genome_scores_df, ratings_df and movies_df to only keep updated movie ID's\n",
    "\n",
    "    def load_all_data(self):\n",
    "        data_loader = DataLoaderPreprocessor()\n",
    "        self.ratings_df, self.movies_full_genome_vector_df, self.movies_df \\\n",
    "            = data_loader.load_and_preprocess_data(self.dataset)\n",
    "\n",
    "        self.movies_genre_binary_term_vector_df, self.movies_lemmatized_genome_vector_df, self.user_int_genre_terms_df, \\\n",
    "        self.user_genre_binary_term_vector_df, self.user_lemmatized_genome_terms_df, self.user_full_genome_terms_df \\\n",
    "            = data_loader.load_and_process_user_data(self.dataset)\n",
    "\n",
    "        self.movie_average_ratings_df = self.ratings_df.loc[:, ['movieId', 'rating']].groupby('movieId').mean()\n",
    "\n",
    "    def get_vector_type_mapping(self, string_vector_type):\n",
    "        \"\"\"\n",
    "\n",
    "        :param string_vector_type:\n",
    "        :raises: ValueError if there's incorrect value in string_vector_type\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        vector_types_dict = {\n",
    "            'genre_binary': BaselineRecommender_VectorType.GENRE_BINARY,\n",
    "            'genre_int': BaselineRecommender_VectorType.GENRE_INTEGER,\n",
    "            'genome_lemmatized': BaselineRecommender_VectorType.GENOME_LEMMATIZED,\n",
    "            'genome_full': BaselineRecommender_VectorType.GENOME_FULL\n",
    "        }\n",
    "\n",
    "        vector_type = vector_types_dict[string_vector_type]\n",
    "\n",
    "        if vector_type is None:\n",
    "            raise ValueError(\"%s is invalid argument, please read documentation for right choice of arguments\")\n",
    "\n",
    "        return vector_types_dict[vector_type]\n",
    "\n",
    "    def recommend_k_most_similar_movies(self, user_id, K, vector_type=BaselineRecommender_VectorType.GENRE_BINARY):\n",
    "        \"\"\"\n",
    "\n",
    "        :param K: Number of best similar movies to recommend\n",
    "        :param vector_type: string {'genre_binary', 'genre_int', 'genome_lemmatized', 'genome_full'}or enum of type BaselineRecommender_VectorType,\n",
    "         with possible values for enum being {GENRE_BINARY, GENRE_INTEGER, GENOME_LEMMATIZED, GENOME_FULL}\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if self.ratings_df is None:\n",
    "            self.load_all_data()\n",
    "\n",
    "        if type(vector_type) is str:\n",
    "            vector_type = self.get_vector_type_mapping(vector_type)\n",
    "\n",
    "        recommend_k_similar_movies = {\n",
    "            BaselineRecommender_VectorType.GENRE_BINARY: self.user_binary_genre_based_recommendations(user_id, K),\n",
    "            BaselineRecommender_VectorType.GENRE_INTEGER: self.user_integer_genre_based_recommendations(user_id, K),\n",
    "            BaselineRecommender_VectorType.GENOME_FULL: self.user_full_genome_based_recommendations(user_id, K),\n",
    "            BaselineRecommender_VectorType.GENOME_LEMMATIZED: self.user_lemmatized_genome_based_recommendations(user_id,\n",
    "                                                                                                                K)\n",
    "        }\n",
    "\n",
    "        return recommend_k_similar_movies[vector_type].tolist()\n",
    "\n",
    "    def user_binary_genre_based_recommendations(self, user_id, K):\n",
    "        return self.genre_based_term_vec_recommendations(user_id, K, self.user_genre_binary_term_vector_df,\n",
    "                                                         self.movies_genre_binary_term_vector_df)\n",
    "\n",
    "    def user_integer_genre_based_recommendations(self, user_id, K):\n",
    "        return self.genre_based_term_vec_recommendations(user_id, K, self.user_int_genre_terms_df,\n",
    "                                                         self.movies_genre_binary_term_vector_df)\n",
    "\n",
    "    def user_full_genome_based_recommendations(self, user_id, K):\n",
    "        return self.genre_based_term_vec_recommendations(user_id, K, self.user_full_genome_terms_df,\n",
    "                                                         self.movies_full_genome_vector_df)\n",
    "\n",
    "    def user_lemmatized_genome_based_recommendations(self, user_id, K):\n",
    "        return self.genre_based_term_vec_recommendations(user_id, K, self.user_lemmatized_genome_terms_df,\n",
    "                                                         self.movies_lemmatized_genome_vector_df)\n",
    "\n",
    "    def genre_based_term_vec_recommendations(self, user_id, K, user_term_vector_df, movies_term_vector_df):\n",
    "        user_term_vector = user_term_vector_df.loc[user_id, :].values.reshape(1, -1)\n",
    "\n",
    "        distances = pairwise_distances(user_term_vector, movies_term_vector_df.values,\n",
    "                                       metric='cosine')\n",
    "\n",
    "        nearest_movies_df = pd.DataFrame(index=movies_term_vector_df.index.values)\n",
    "        nearest_movies_df['distances'] = distances.reshape(-1, 1)\n",
    "\n",
    "        # ties in ranking are breaked based on average rating across all users\n",
    "        nearest_movies_df['avg_rating'] = self.movie_average_ratings_df['rating']\n",
    "        nearest_movies_df.sort_values(['distances', 'avg_rating'], ascending=False, inplace=True)\n",
    "\n",
    "        return nearest_movies_df.index.values[:K]\n",
    "\n",
    "\n",
    "# TODO create enum to allow selection between ranking algorithms\n",
    "class RankingEnum:\n",
    "    pass\n",
    "\n",
    "\n",
    "class CB_ClusteringBased_Recommender:\n",
    "    # TODO normalize values in ranking dataframe before reranking them.\n",
    "    #   and compare results with non-normalized one\n",
    "    # TODO p-median problem to infer user's taste based on tag-genomes.\n",
    "\n",
    "    def __init__(self, ratings_df, genome_scores_df, user_term_vector_df, item_item_similarities_df, K=20,\n",
    "                 n_neighbours=50, n_clusters=8, relevant_movies_threshold=0.2, random_state=171450):\n",
    "        \"\"\"\n",
    "\n",
    "        :param ratings_df: Ratings df, original as read from Movielens dataset\n",
    "        :param genome_scores_df: Genome scores dataframe,\n",
    "            pivoted as index='movieId', columns='tagId', values='relevance'\n",
    "        :param user_term_vector_df: Pandas Dataframe of User Genome Term Vector\n",
    "        :param K: Recommend top K movies\n",
    "        :param n_neighbours: Number of neighbor movies to consider for each candidate movie\n",
    "        :param n_clusters: Number of clusters to be formed\n",
    "        \"\"\"\n",
    "        self.ratings_df = ratings_df\n",
    "        self.genome_scores_df = genome_scores_df\n",
    "        self.user_term_vector_df = user_term_vector_df\n",
    "        self.K = K\n",
    "        self.n_neighbours = n_neighbours\n",
    "        self.item_item_similarities_df = item_item_similarities_df\n",
    "        self.relevant_movies_threshold = relevant_movies_threshold\n",
    "\n",
    "        # Weighted ranking\n",
    "        # TODO - remove hardcoding\n",
    "        self.Rcu_weight = 0.40\n",
    "        self.Su_weight = 0.20\n",
    "        self.div_weight = 0.15\n",
    "        self.Ci_weight = 0.15\n",
    "\n",
    "        # TODO do all the necessary preprocessing under this method\n",
    "        self.preprocess_data()\n",
    "\n",
    "    def set_ranking_weights(self, Rcu_weight, Su_weight, div_weight, Ci_weight):\n",
    "        self.Rcu_weight = Rcu_weight\n",
    "        self.Su_weight = Su_weight\n",
    "        self.div_weight = div_weight\n",
    "        self.Ci_weight = Ci_weight\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        # TODO choose movies only above threshold_rating\n",
    "        # TODO omit movies without genres (no genres listed) - to compare with genre based approach\n",
    "        pass\n",
    "\n",
    "    def recommend_movies(self, user_id, K=None):\n",
    "        # TODO choose movies only above threshold_rating\n",
    "        # TODO omit movies without genres (no genres listed) - to compare with genre based approach\n",
    "        if K is not None:\n",
    "            self.K = K\n",
    "\n",
    "        # extract list of movies watched by this user\n",
    "        user_movies_d = self.get_users_watched_movies(user_id)\n",
    "\n",
    "        # extract tag-genomes for movies watched by user\n",
    "        user_movie_tags_df = self.genome_scores_df[self.genome_scores_df.index.isin(user_movies_d[user_id])]\n",
    "\n",
    "        # create clusters_series for movies watched by user\n",
    "        clusters_series = self.form_clusters(user_id, user_movies_d, user_movie_tags_df)\n",
    "\n",
    "        # select right clusters_series to target:\n",
    "        # TODO udpate optimal cluster selection technique\n",
    "        target_clusters, cluster_ranks, above_mean_cluster_index, below_mean_cluster_index \\\n",
    "            = self.choose_appropriate_clusters_for_diversification(clusters_series)\n",
    "\n",
    "        # decide ratio of movies selected from similar clusters to movies selected from sparse clusters\n",
    "        N_movies_similar = int(self.K * self.relevant_movies_threshold)\n",
    "        # TODO fix this, when K=8, this is being 0 for user ID 1 on ml20m dataset,\n",
    "        #  failing only for full-genome df, not for lemmatized, check why not failing for lemmatized\n",
    "        #   divide by zero error in some cases, unknown cases though\n",
    "        N_movies_per_dense_cluster = int(N_movies_similar / above_mean_cluster_index.size)\n",
    "\n",
    "        # existing greedy re-ranking approach for movies in sparse clusters\n",
    "        N_movies_diverse = self.K - N_movies_similar\n",
    "\n",
    "        # TODO figure out better way to remove duplicate movies from recommendations\n",
    "\n",
    "        # RL1 - Recommendation List from Dense clusters\n",
    "        dense_cluster_recommendations = list()\n",
    "\n",
    "        # fetch n_neighbors for each movie in target_clusters\n",
    "        previous_recommendations_count = N_movies_per_dense_cluster  # denotes number of movies recommended from previous cluster\n",
    "        for cluster in above_mean_cluster_index:\n",
    "            # find best K movies for each movie in a cluster\n",
    "            # TODO rank according to highest diversity or decide best approach to re-rank these movies\n",
    "\n",
    "            # movies from this cluster\n",
    "            watched_movies = clusters_series[cluster]\n",
    "            # if less movies are recommended from previous cluster(s), automatically recommend N extra movies\n",
    "            N_movies = N_movies_per_dense_cluster + max(0, N_movies_per_dense_cluster - previous_recommendations_count)\n",
    "\n",
    "            recommended_movies = self.find_similar_movies_to_dense_cluster(watched_movies, user_id, N_movies)\n",
    "            dense_cluster_recommendations.extend(recommended_movies.tolist())\n",
    "\n",
    "            # actual number of movies recommended from this cluster\n",
    "            # difference indicates N movies yet to be recommended\n",
    "            previous_recommendations_count = recommended_movies.size\n",
    "\n",
    "        # In case if movies recommended form dense clusters are less than intended\n",
    "        N_movies_diverse = N_movies_diverse + len(dense_cluster_recommendations) - N_movies_similar\n",
    "\n",
    "        # greedy-re-ranking algorithm, based on rating, diversity, similarity to watched and user profile.\n",
    "        # movies from this cluster\n",
    "        # RL2 - Recommendation List from Sparse clusters\n",
    "        sparse_cluster_recommendations = list()\n",
    "\n",
    "        # get all watched movies from clusters below mean\n",
    "        watched_movies = list()\n",
    "        for cluster in below_mean_cluster_index:\n",
    "            watched_movies.extend(clusters_series[cluster])\n",
    "\n",
    "        sparse_cluster_recommendations.extend(\n",
    "            self.find_similar_movies_to_sparse_cluster(watched_movies, user_id, N_movies_diverse, clusters_series))\n",
    "\n",
    "        # rank similar movies for each cluster, and select top-N from each cluster\n",
    "        # duplicate processing, keep one with the top cluster rank\n",
    "        dense_cluster_recommendations.extend(sparse_cluster_recommendations)\n",
    "\n",
    "        return dense_cluster_recommendations\n",
    "\n",
    "    def find_similar_movies_to_sparse_cluster(self, watched_movies, user_id, N_movies_diverse, clusters_series):\n",
    "        # TODO do experiment by changing R_cu to be average rating across all users rather than\n",
    "        # TODO figure out better way to remove duplicate movies from recommendations\n",
    "        # TODO test\n",
    "        ranking_df = pd.DataFrame()\n",
    "\n",
    "        for watched_movie_id in watched_movies:\n",
    "            similar_movies = self.item_item_similarities_df[watched_movie_id].sort_values(ascending=False)[\n",
    "                             :self.n_neighbours]\n",
    "\n",
    "            similar_movies_df = pd.DataFrame(similar_movies)\n",
    "            similar_movies_df['movieId'] = similar_movies_df.index\n",
    "            similar_movies_df['watched_movie_id'] = similar_movies.name\n",
    "            similar_movies_df.columns = ['S_c', 'movieId', 'watched_movie_id']\n",
    "\n",
    "            similar_movies_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            ranking_df = ranking_df.append(similar_movies_df, ignore_index=True)\n",
    "\n",
    "        movie_ids = ranking_df['movieId'].values\n",
    "\n",
    "        # extract genome scores for movie_ids\n",
    "        genome_scores_vector = self.user_term_vector_df.loc[movie_ids, :].values\n",
    "\n",
    "        # extract user_term vector\n",
    "        user_vector = self.user_term_vector_df.loc[user_id, :]\n",
    "\n",
    "        distances_with_user = pairwise_distances(genome_scores_vector, [user_vector], metric='cosine')\n",
    "\n",
    "        ranking_df['S_u'] = distances_with_user\n",
    "        ranking_df['diversity'] = 1 - ranking_df['S_u']\n",
    "\n",
    "        users_ratings = self.ratings_df[self.ratings_df['userId'] == user_id].loc[:, ['movieId', 'rating']]\n",
    "        candidate_movie_ratings_df = users_ratings[users_ratings['movieId'].isin(watched_movies)]\n",
    "        candidate_movie_ratings_df.set_index(candidate_movie_ratings_df['movieId'].values, drop=True, inplace=True)\n",
    "\n",
    "        movie_ratings_dict = candidate_movie_ratings_df['rating'].to_dict()\n",
    "\n",
    "        def assign_rating(x):\n",
    "            x['R_cu'] = movie_ratings_dict[x['watched_movie_id']]\n",
    "\n",
    "            return x\n",
    "\n",
    "        ranking_df['R_cu'] = None\n",
    "\n",
    "        ranking_df = ranking_df.apply(lambda x: assign_rating(x), axis=1)\n",
    "\n",
    "        # add cluster rank as well, remove this line\n",
    "        # ranks = ranking_df.loc[:, ['S_c', 'S_u', 'diversity', 'R_cu']].rank(method='dense')\n",
    "\n",
    "        # cluster_size_df\n",
    "        cluster_size_df = pd.DataFrame(index=clusters_series.index)\n",
    "\n",
    "        def process(x):\n",
    "            x['size'] = len(clusters_series[x.name])\n",
    "\n",
    "            return x\n",
    "\n",
    "        cluster_size_df['size'] = None\n",
    "        cluster_size_df = cluster_size_df.apply(lambda x: process(x), axis=1)\n",
    "\n",
    "        # smaller the cluster size, higher the score\n",
    "        cluster_size_df['C_i'] = cluster_size_df.rank(method='dense', ascending=False).astype(np.int)\n",
    "\n",
    "        def assign_cluster_score(x):\n",
    "            x['C_i'] = self.get_movie_cluster_score(x['watched_movie_id'], clusters_series, cluster_size_df)\n",
    "            return x\n",
    "\n",
    "        ranking_df['C_i'] = None\n",
    "        ranking_df = ranking_df.apply(lambda x: assign_cluster_score(x), axis=1)\n",
    "\n",
    "        # ranking formula\n",
    "        # The '\\' sign indicates continuation of code from next line\n",
    "        # TODO rework on this equation,\n",
    "        #   consider something like (R_cu * rank(R_cu) + diversity * rank(diversity) + (S_u) * rank(S_u) + (S_c) * rank(S_c) + C_i\n",
    "        # TODO ranking experiment-1\n",
    "        # ranking_df['composite_score'] = ranking_df['R_cu'] * ranking_df['diversity'] \\\n",
    "        #                                 * ranking_df['S_u'] * ranking_df['S_c'] * ranking_df['C_i']\n",
    "        #\n",
    "        # sorted_scores_df = ranking_df.sort_values('composite_score', ascending=False)\n",
    "        # sorted_scores_df.to_csv(data_output_dir + \"ranking_composite1.csv\")\n",
    "\n",
    "        ranking_df['rank(R_cu)'] = ranking_df['R_cu'].rank(method='dense')\n",
    "        ranking_df['rank(diversity)'] = ranking_df['diversity'].rank(method='dense')\n",
    "        ranking_df['rank(S_u)'] = ranking_df['S_u'].rank(method='dense')\n",
    "        ranking_df['rank(S_c)'] = ranking_df['S_c'].rank(method='dense')\n",
    "\n",
    "        # TODO rework on this equation,\n",
    "        #   consider something like (R_cu * rank(R_cu) + diversity * rank(diversity) + (S_u) * rank(S_u) + (S_c) * rank(S_c) + C_i\n",
    "        # TODO check difference in df rank reordering with that from above formula\n",
    "        # TODO ranking experiment-2\n",
    "        # ranking_df['composite_score'] = ranking_df['R_cu'] * ranking_df['rank(R_cu)'] + ranking_df['diversity'] * \\\n",
    "        #                                 ranking_df['rank(diversity)'] \\\n",
    "        #                                 + ranking_df['S_u'] * ranking_df['rank(S_u)'] + ranking_df['S_c'] * ranking_df[\n",
    "        #                                     'rank(S_c)'] + ranking_df['C_i']\n",
    "        #\n",
    "        # sorted_scores_df = ranking_df.sort_values('composite_score', ascending=False)\n",
    "        # sorted_scores_df.to_csv(data_output_dir + \"ranking_composite2.csv\")\n",
    "        #\n",
    "        # # TODO ranking experiment-3:\n",
    "        # ranking_df.drop(['composite_score', 'rank(R_cu)', 'rank(diversity)', 'rank(S_u)', 'rank(S_c)'], axis=1,\n",
    "        #                 inplace=True)\n",
    "        # exp3_df = ranking_df.sort_values(['S_c', 'S_u', 'diversity', 'R_cu', 'C_i'], ascending=False)\n",
    "        # exp3_df.to_csv(data_output_dir + \"ranking_composite3.csv\")\n",
    "        #\n",
    "        # exp4_df = ranking_df.sort_values(['S_c', 'diversity', 'S_u', 'C_i', 'R_cu'], ascending=False)\n",
    "        # exp3_df.to_csv(data_output_dir + \"ranking_composite4.csv\")\n",
    "        #\n",
    "        # print(\"Dataframes similarity:\", exp3_df.equals(exp4_df))\n",
    "\n",
    "        # TODO ranking experiment4:\n",
    "        ranking_df['composite_score_weighted'] = self.Rcu_weight * ranking_df['rank(R_cu)'] \\\n",
    "                                                 + self.div_weight * ranking_df['rank(diversity)'] \\\n",
    "                                                 + self.Su_weight * ranking_df['rank(S_u)'] \\\n",
    "                                                 + self.Ci_weight * ranking_df['C_i']\n",
    "\n",
    "        sorted_scores_df = ranking_df.sort_values('composite_score_weighted', ascending=False)\n",
    "\n",
    "        # drop duplicates\n",
    "        sorted_scores_df.set_index(sorted_scores_df['movieId'].values, drop=True, inplace=True)\n",
    "        sorted_scores_df.drop(columns='movieId', inplace=True)\n",
    "        sorted_scores_df['m_id'] = sorted_scores_df.index.values\n",
    "        sorted_scores_df.drop_duplicates('m_id', inplace=True)\n",
    "        sorted_scores_df.drop(columns='m_id', inplace=True)\n",
    "\n",
    "        return sorted_scores_df.index.values[:N_movies_diverse].reshape(1, -1)[0]\n",
    "\n",
    "    @staticmethod\n",
    "    def get_movie_cluster_score(movieId, clusters_series, cluster_size_df):\n",
    "        for cluster in clusters_series.index.tolist():\n",
    "            if movieId in clusters_series[cluster]:\n",
    "                return cluster_size_df.loc[cluster, ['C_i']].values[0]\n",
    "\n",
    "        return 0\n",
    "\n",
    "    def find_similar_movies_to_dense_cluster(self, watched_movies, user_id, N_movies_per_dense_cluster):\n",
    "        # TODO figure out better way to remove duplicate movies from recommendations\n",
    "        # TODO test\n",
    "        ranking_df = pd.DataFrame()\n",
    "\n",
    "        for watched_movie_id in watched_movies:\n",
    "            # sort by most similar movies on top\n",
    "            similar_movies = self.item_item_similarities_df[watched_movie_id].sort_values(ascending=False)[:self.K]\n",
    "\n",
    "            similar_movies_df = pd.DataFrame(similar_movies)\n",
    "            similar_movies_df['movieId'] = similar_movies_df.index\n",
    "            # similar_movies_df['watched_movie_id'] = similar_movies.name\n",
    "            similar_movies_df.columns = ['S_c', 'movieId']\n",
    "            similar_movies_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            ranking_df = ranking_df.append(similar_movies_df, ignore_index=True)\n",
    "\n",
    "        movie_ids = ranking_df['movieId'].values\n",
    "\n",
    "        # extract genome scores for movie_ids\n",
    "        genome_scores_vector = self.genome_scores_df.loc[movie_ids, :].values\n",
    "\n",
    "        # extract user_term vector\n",
    "        user_vector = self.user_term_vector_df.loc[user_id, :]\n",
    "\n",
    "        distances_with_user = pairwise_distances(genome_scores_vector, [user_vector], metric='cosine')\n",
    "\n",
    "        # similarity to user profile\n",
    "        ranking_df['S_u'] = distances_with_user\n",
    "\n",
    "        # diversity\n",
    "        ranking_df['diversity'] = 1 - ranking_df['S_u']\n",
    "\n",
    "        # sort as per highest diversity offered\n",
    "        # TODO rethink on how to rerank these movies, whether by max diversity, or by similarity to watched_movie or similarity to user profile\n",
    "        #   or whether multiple columns should be considered while ranking these movies\n",
    "        ranking_df.sort_values('diversity', ascending=False, inplace=True)\n",
    "\n",
    "        # TODO replace this approach with better way of dropping duplicates\n",
    "        ranking_df.set_index(ranking_df['movieId'].values, drop=True, inplace=True)\n",
    "        ranking_df.drop(columns='movieId', inplace=True)\n",
    "        ranking_df['m_id'] = ranking_df.index.values\n",
    "        ranking_df.drop_duplicates('m_id', inplace=True)\n",
    "        ranking_df.drop(columns='m_id', inplace=True)\n",
    "\n",
    "        return ranking_df.index.values[:N_movies_per_dense_cluster].reshape(1, -1)[0]\n",
    "\n",
    "    def fetch_n_neighbors_for_target_clusters(self, target_clusters, all_cluster):\n",
    "        \"\"\"\n",
    "\n",
    "        :param target_clusters:\n",
    "        :param all_clusters: original all_clusters series\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # list all movie id's from target clusters:\n",
    "        all_candidate_movies = list()\n",
    "\n",
    "        for cluster in target_clusters:\n",
    "            all_candidate_movies.extend(all_cluster[cluster].values.tolist())\n",
    "\n",
    "    def fetch_N_similar_movies(self, candidate_movie_id):\n",
    "        \"\"\"\n",
    "        :param candidate_movie_id:\n",
    "        :return: Pandas Series with movieId as Index and relevance score to candidate movie as values\n",
    "        \"\"\"\n",
    "        return self.item_item_similarities_df[candidate_movie_id].sort_values(ascending=False)[:self.n_neighbours]\n",
    "\n",
    "    def choose_appropriate_clusters_for_diversification(self, clusters):\n",
    "        \"\"\"\n",
    "        Choose appropriate cluster to do diversification\n",
    "        :param clusters:\n",
    "        :return:Array of cluster number below threshold,\n",
    "                and\n",
    "                Array of their respective ranks\n",
    "        \"\"\"\n",
    "        cluster_size_df = pd.DataFrame(index=clusters.index)\n",
    "\n",
    "        def process(x):\n",
    "            x['size'] = len(clusters[x.name])\n",
    "\n",
    "            return x\n",
    "\n",
    "        cluster_size_df['size'] = None\n",
    "\n",
    "        # calculate & store size for each cluster\n",
    "        cluster_size_df.apply(lambda x: process(x), axis=1)\n",
    "\n",
    "        # choose clusters with only up to median sizes\n",
    "        # choosing all clusters\n",
    "        below_mean_clusters_df = cluster_size_df[cluster_size_df['size'] <= cluster_size_df['size'].mean()]\n",
    "        below_mean_cluster_index = below_mean_clusters_df.index.values\n",
    "\n",
    "        above_mean_cluster_index = np.setdiff1d(cluster_size_df.index.values, below_mean_cluster_index)\n",
    "\n",
    "        # rank clusters\n",
    "        cluster_size_df['rank'] = cluster_size_df.rank(method='dense')\n",
    "\n",
    "        return cluster_size_df.index.values, cluster_size_df[\n",
    "            'rank'].values, above_mean_cluster_index, below_mean_cluster_index\n",
    "\n",
    "    def form_clusters(self, user_id, user_movies_d, user_movie_tags_df):\n",
    "        # TODO filter movies only above certain rating threshold\n",
    "        n_movies = user_movie_tags_df.index.size\n",
    "        highest_score = 0\n",
    "\n",
    "        best_clustering_result = None\n",
    "\n",
    "        # exhaustively check silhouette scores for each cluster sizes and select the cluster size with the highest score.\n",
    "        for cluster_size in range(2, n_movies - 1, 1):\n",
    "            clustering_result = AgglomerativeClustering(n_clusters=cluster_size, affinity='euclidean',\n",
    "                                                        linkage='ward').fit_predict(\n",
    "                user_movie_tags_df.values[:n_movies])\n",
    "            score = silhouette_score(user_movie_tags_df.values[:n_movies], clustering_result)\n",
    "\n",
    "            if highest_score < score:\n",
    "                best_clustering_result = clustering_result\n",
    "                highest_score = score\n",
    "\n",
    "        new_df = pd.DataFrame(best_clustering_result, columns=['cluster'])\n",
    "\n",
    "        new_df['movie'] = user_movies_d[user_id]\n",
    "        resulting_clusters = new_df.groupby('cluster')['movie'].apply(list)\n",
    "\n",
    "        return resulting_clusters\n",
    "\n",
    "    def get_users_watched_movies(self, user_id):\n",
    "        user_movies_d = {}\n",
    "\n",
    "        user_movies_d[user_id] = self.ratings_df[self.ratings_df['userId'] == user_id]['movieId'].values.tolist()\n",
    "\n",
    "        return user_movies_d\n",
    "\n",
    "\n",
    "def top_K_similar_movies(user_id, K, all_movies_vector, user_genome_vector_df, genome_scores_df):\n",
    "    all_movies_vector = genome_scores_df.values\n",
    "\n",
    "    user_vector = user_genome_vector_df.loc[user_id, :].values\n",
    "\n",
    "    # convert from 1D to 2D array\n",
    "    user_vector = np.array([user_vector])\n",
    "\n",
    "    distances = pairwise_distances(all_movies_vector, user_vector, metric='cosine')\n",
    "\n",
    "    # 2D to 1D\n",
    "    distances = distances.T[0]\n",
    "\n",
    "    ser = pd.Series(distances, name=user_id)\n",
    "    ser.index = genome_scores_df.index\n",
    "\n",
    "    # top K recommendations, with relevance scores to the user profile\n",
    "    return ser.sort_values(ascending=False)[:K]\n",
    "\n",
    "\n",
    "def main():\n",
    "    user_genome_vector_df = pd.read_pickle(user_unstemmed_genome_vector, compression='gzip')\n",
    "    print(user_genome_vector_df.head())\n",
    "\n",
    "    user_terms = user_genome_vector_df.values\n",
    "    # chunked_D = pairwise_distances_chunked(user_terms, metric='cosine')\n",
    "\n",
    "    genome_scores_df = pd.read_csv(genome_scores)\n",
    "    genome_scores_df = genome_scores_df.pivot(index='movieId', columns='tagId', values='relevance')\n",
    "    # genome_score_movies = genome_scores_df['movieId'].unique()\n",
    "    genome_score_movies = genome_scores_df.index.unique().values\n",
    "\n",
    "    ratings_df = pd.read_csv(ratings, usecols=range(3),\n",
    "                             dtype={'userId': np.int64, 'movieId': np.int64, 'rating': np.float64}, low_memory=False)\n",
    "    # only keep ratings for which the genome scores exists\n",
    "    ratings_df = ratings_df[ratings_df['movieId'].isin(genome_score_movies)]\n",
    "\n",
    "    item_terms = genome_scores_df.values\n",
    "    user_terms = user_genome_vector_df.values\n",
    "\n",
    "    item_terms = genome_scores_df.values\n",
    "    item_item_distances = pairwise_distances(item_terms, metric='cosine')\n",
    "    item_item_similarity_df = pd.DataFrame(item_item_distances, index=genome_scores_df.index,\n",
    "                                           columns=genome_scores_df.index)\n",
    "    print(item_item_distances)\n",
    "\n",
    "    # recommender = ContentBased_Baseline_Recommender()\n",
    "    recommender = CB_ClusteringBased_Recommender(ratings_df, genome_scores_df, user_genome_vector_df,\n",
    "                                                 item_item_similarity_df, n_neighbours=8)\n",
    "    # predict ratings for all users in serendipity dataset\n",
    "    start_time = time()\n",
    "    for user_id in range(1, 6):\n",
    "        print(user_id)\n",
    "        recommended_movies = recommender.recommend_movies(user_id)\n",
    "        print(recommended_movies)\n",
    "    finish_time = time() - start_time\n",
    "\n",
    "    print(\"Total Time Taken: %f seconds\" % finish_time)\n",
    "\n",
    "    # load df from answers\n",
    "    # answers_df = pd.read_csv(answers)\n",
    "    # user_list = answers_df['userId'].unique().tolist()\n",
    "\n",
    "    # final_recommendations_df = pd.DataFrame(columns=['userId', 'movieId'])\n",
    "    #\n",
    "    # for user_id in user_list[:5]:\n",
    "    #     # predict ratings for all users in serendipity dataset\n",
    "    #     recommended_movies = recommender.recommend_movies(user_id, K=8)\n",
    "    #\n",
    "    #     recommendations_df = pd.DataFrame(index=range(1, 9))\n",
    "    #     recommendations_df['userId'] = user_id\n",
    "    #     recommendations_df['movieId'] = recommended_movies\n",
    "    #\n",
    "    #     print(recommended_movies)\n",
    "    #     final_recommendations_df = final_recommendations_df.append(recommendations_df, ignore_index=True)\n",
    "    #\n",
    "    # final_recommendations_df.to_csv(data_output_dir + \"final_recommendations.csv\")\n",
    "    # print(final_recommendations_df)\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading data: movies, ratings, genome-scores...\n",
      "Preprocessing data: movies, ratings, genome-scores...\n",
      "\n",
      "Loading generated data: genre, genome-lemmatized, genome-full term vectors for users and movies...\n",
      "Preprocessing generated data: genre, genome-lemmatized, genome-full term vectors for users and movies...\n",
      "\n",
      "Main Model Lemmatized results:\n",
      " [6132, 64037, 112091, 5891, 50189, 96691, 6036, 6775, 5781, 1862, 559, 3472, 113345, 4982, 74154, 6599, 112091, 34150, 109189, 8785]\n",
      "\n",
      "Main Model full-genome results:\n",
      " [64037, 6132, 4752, 4645, 96691, 44193, 6775, 3472, 6144, 80860, 39441, 701, 4069, 6041, 48600, 49286, 56949, 88950, 8785, 2632]\n",
      "\n",
      "Main Model Lemmatized results:\n",
      " [8675, 33750, 8608, 5919, 108778, 104441, 64037, 85367, 45635, 81751, 5363, 27564, 72407, 101281, 6550, 108981, 108727, 1116, 97744, 3272]\n",
      "\n",
      "Main Model full-genome results:\n",
      " [80363, 72407, 108778, 33815, 5363, 55232, 5157, 66639, 6748, 5717, 81751, 5189]\n",
      "\n",
      "Main Model Lemmatized results:\n",
      " [106072, 70336, 6564, 72378, 5781, 63, 3472, 559, 44193, 59022, 96691, 1862, 50189, 6036, 112091, 113345, 92264, 2557, 5153, 7439]\n",
      "\n",
      "Main Model full-genome results:\n",
      " [113345, 106072, 27618, 102125, 3472, 44193, 96691, 4069, 4887, 113345, 27664, 102072, 108778, 66639, 92264, 86835, 559, 8142, 36519, 95543]\n",
      "\n",
      "Main Model Lemmatized results:\n",
      " [1939, 1936, 1933, 3808, 96691, 113345, 5781, 3472, 108778, 559, 1862, 112091, 69526, 44193, 6036, 112370, 50189, 86835, 80363, 3847]\n",
      "\n",
      "Main Model full-genome results:\n",
      " [64114, 6450, 111249, 94018, 96691, 108778, 44193, 3472, 69526, 559, 113345, 86835, 102072, 6775, 66639, 112370, 127298, 5351, 27664, 3216]\n",
      "\n",
      "Main Model Lemmatized results:\n",
      " [1939, 1936, 1933, 3808, 5781, 44193, 108778, 3472, 559, 1862, 3847, 96691, 113345, 50189, 6036, 112091, 63992, 92264, 64037, 95543]\n",
      "\n",
      "Main Model full-genome results:\n",
      " [6264, 101076, 87520, 27618, 108778, 44193, 3472, 4069, 559, 96691, 102072, 66639, 3216, 5351, 92264, 64037, 5620, 86835, 8911, 27664]\n",
      "\n",
      "Main Model Lemmatized results:\n",
      " [31030, 51638, 1939, 1936, 3847, 3472, 80363, 64037, 108778, 5781, 559, 50189, 6550, 1862, 69526, 108727, 3216, 113345, 78467, 87520]\n",
      "\n",
      "Main Model full-genome results:\n",
      " [4310, 102072, 3472, 44193, 3847, 92206, 108778, 69526, 5951, 3216, 5269, 8785]\n",
      "experimental_users_list:  [9, 10, 11, 12, 13, 14]\n",
      "recommendation_results_dict dictionary:\n",
      " {'main_model_lemmatized': [[6132, 64037, 112091, 5891, 50189, 96691, 6036, 6775, 5781, 1862, 559, 3472, 113345, 4982, 74154, 6599, 112091, 34150, 109189, 8785], [8675, 33750, 8608, 5919, 108778, 104441, 64037, 85367, 45635, 81751, 5363, 27564, 72407, 101281, 6550, 108981, 108727, 1116, 97744, 3272], [106072, 70336, 6564, 72378, 5781, 63, 3472, 559, 44193, 59022, 96691, 1862, 50189, 6036, 112091, 113345, 92264, 2557, 5153, 7439], [1939, 1936, 1933, 3808, 96691, 113345, 5781, 3472, 108778, 559, 1862, 112091, 69526, 44193, 6036, 112370, 50189, 86835, 80363, 3847], [1939, 1936, 1933, 3808, 5781, 44193, 108778, 3472, 559, 1862, 3847, 96691, 113345, 50189, 6036, 112091, 63992, 92264, 64037, 95543], [31030, 51638, 1939, 1936, 3847, 3472, 80363, 64037, 108778, 5781, 559, 50189, 6550, 1862, 69526, 108727, 3216, 113345, 78467, 87520]], 'main_model_full': [[64037, 6132, 4752, 4645, 96691, 44193, 6775, 3472, 6144, 80860, 39441, 701, 4069, 6041, 48600, 49286, 56949, 88950, 8785, 2632], [80363, 72407, 108778, 33815, 5363, 55232, 5157, 66639, 6748, 5717, 81751, 5189], [113345, 106072, 27618, 102125, 3472, 44193, 96691, 4069, 4887, 113345, 27664, 102072, 108778, 66639, 92264, 86835, 559, 8142, 36519, 95543], [64114, 6450, 111249, 94018, 96691, 108778, 44193, 3472, 69526, 559, 113345, 86835, 102072, 6775, 66639, 112370, 127298, 5351, 27664, 3216], [6264, 101076, 87520, 27618, 108778, 44193, 3472, 4069, 559, 96691, 102072, 66639, 3216, 5351, 92264, 64037, 5620, 86835, 8911, 27664], [4310, 102072, 3472, 44193, 3847, 92206, 108778, 69526, 5951, 3216, 5269, 8785]], 'baseline_genre_binary': [[127206, 50, 904, 750, 1212, 1198, 3030, 100553, 1284, 5618, 1252, 1260, 260, 1196, 913, 2571, 950, 1248, 1148, 4226], [3037, 7210, 4329, 82459, 2921, 3074, 2401, 6429, 3311, 5440, 8334, 3487, 5435, 6617, 31485, 25938, 6409, 44168, 6356, 5199], [100553, 913, 1147, 1189, 120478, 2066, 1361, 3077, 8228, 3677, 246, 58425, 85774, 7566, 1258, 602, 162, 96606, 80906, 7096], [100553, 913, 1147, 1189, 120478, 2066, 1361, 3077, 8228, 3677, 246, 58425, 85774, 7566, 602, 162, 96606, 80906, 7096, 114635], [100553, 1284, 913, 1147, 1189, 2859, 120478, 2066, 942, 2726, 1361, 3077, 8228, 3677, 246, 58425, 85774, 7566, 602, 162], [2066, 4426, 7335, 5169, 746, 3292, 1154, 1153, 3380, 5795, 72090, 91697, 99444, 110510, 913, 2726, 4432, 5017, 2612, 7943]], 'baseline_genre_int': [[127206, 50, 904, 750, 1212, 1198, 3030, 100553, 1284, 5618, 1252, 1260, 260, 1196, 913, 2571, 950, 1248, 1148, 4226], [3037, 7210, 4329, 82459, 2921, 3074, 2401, 6429, 3311, 5440, 8334, 3487, 5435, 6617, 31485, 25938, 6409, 44168, 6356, 5199], [100553, 913, 1147, 1189, 120478, 2066, 1361, 3077, 8228, 3677, 246, 58425, 85774, 7566, 1258, 602, 162, 96606, 80906, 7096], [100553, 913, 1147, 1189, 120478, 2066, 1361, 3077, 8228, 3677, 246, 58425, 85774, 7566, 602, 162, 96606, 80906, 7096, 114635], [100553, 1284, 913, 1147, 1189, 2859, 120478, 2066, 942, 2726, 1361, 3077, 8228, 3677, 246, 58425, 85774, 7566, 602, 162], [2066, 4426, 7335, 5169, 746, 3292, 1154, 1153, 3380, 5795, 72090, 91697, 99444, 110510, 3037, 7210, 4329, 82459, 2921, 3074]], 'baseline_genome_lemmatized': [[4271, 5687, 6107, 33750, 1315, 77833, 50619, 31702, 2933, 2669, 6818, 26246, 101207, 26231, 3670, 5794, 58876, 1534, 5614, 6123], [115414, 74075, 104312, 110809, 73106, 3216, 3804, 39421, 59429, 92938, 3691, 53464, 6036, 87430, 559, 77414, 4974, 51077, 7317, 2894], [1315, 4271, 5687, 50619, 3216, 26231, 6107, 33750, 77833, 4872, 2933, 31702, 6818, 26241, 1534, 5794, 2669, 108778, 26246, 27114], [3216, 26231, 26241, 1315, 50619, 4872, 2894, 108981, 559, 5687, 7024, 4271, 5351, 5794, 3804, 7976, 6036, 3621, 69134, 110809], [3216, 26231, 26241, 4271, 50619, 1315, 5687, 2894, 559, 108981, 7024, 4872, 5794, 5351, 3472, 3621, 3804, 69134, 4752, 6036], [3216, 26241, 64037, 5891, 2894, 26231, 559, 4752, 7024, 108981, 4872, 3804, 5569, 7976, 6132, 3272, 69134, 1315, 3472, 495]], 'baseline_genome_full': [[5687, 1315, 1534, 2933, 4271, 5614, 3242, 50619, 5351, 2632, 787, 3687, 26743, 33750, 6160, 6123, 4237, 33124, 4347, 6107], [104312, 115414, 74075, 77414, 110809, 97785, 43930, 3216, 5413, 5687, 96691, 1315, 54734, 63393, 80363, 3687, 39421, 88108, 5351, 73106], [5687, 1315, 1534, 2933, 4271, 50619, 5614, 27114, 4884, 5351, 2632, 5473, 3216, 3242, 787, 47274, 33124, 33750, 6599, 4237], [5687, 1315, 5351, 3216, 1534, 4271, 50619, 2632, 2933, 4752, 3242, 3621, 5413, 4884, 3472, 26231, 7024, 5473, 872, 26241], [5687, 1315, 4271, 5351, 3216, 1534, 2632, 50619, 2933, 5413, 3242, 3621, 4752, 3472, 872, 26231, 26241, 5794, 4884, 7024], [4752, 5413, 5687, 3216, 6132, 5891, 5717, 8906, 1315, 7024, 3621, 3472, 5351, 5569, 3652, 4271, 96691, 4884, 3344, 1534]]}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "evaluate_all_models() missing 1 required positional argument: 'N_recommendations'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d591c2ab8580>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;31m# evaluate all models and produce results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m \u001b[0mevaluate_all_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperimental_users_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecommendation_results_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: evaluate_all_models() missing 1 required positional argument: 'N_recommendations'"
     ]
    }
   ],
   "source": [
    "# class Serendipity\n",
    "import numpy as np\n",
    "from enum import Enum\n",
    "import pandas as pd\n",
    "# import CB_ClusteringBased_Recommender, ContentBased_Baseline_Recommender, \\\n",
    "#     BaselineRecommender_VectorType\n",
    "# from DataLoaderPreprocessor import DataLoaderPreprocessor\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "base_dir = '../../datasets/Movielens/'\n",
    "\n",
    "ml20m = base_dir + 'ml-20m/'\n",
    "serendipity2018 = base_dir + 'serendipity-sac2018/'\n",
    "\n",
    "data_dir2 = serendipity2018\n",
    "answers = serendipity2018 + 'answers.csv'\n",
    "\n",
    "data_output_dir = base_dir + 'output/'\n",
    "\n",
    "\n",
    "def evaluate_recommendations(user_id, recommendation_list, N_size, movie_genome_scores_df, user_genome_terms_df):\n",
    "    movie_genomes_df = movie_genome_scores_df.loc[recommendation_list, :]\n",
    "    user_vector_df = user_genome_terms_df.loc[user_id, :].values.reshape(1, -1)\n",
    "\n",
    "    model_pairwise_scores_df = pd.DataFrame(index=recommendation_list)\n",
    "    model_pairwise_scores_df['similarity'] = pairwise_distances(user_vector_df, movie_genomes_df.values,\n",
    "                                                                metric='cosine').reshape(-1, 1)\n",
    "    model_pairwise_scores_df['diversity'] = 1 - model_pairwise_scores_df['similarity']\n",
    "\n",
    "    all_movies = model_pairwise_scores_df.index.values\n",
    "    movie_genomes_df = movie_genome_scores_df.loc[all_movies, :]\n",
    "\n",
    "    # calculating diversity of a list (1-SIM_ij)\n",
    "    intra_list_distances_df = pd.DataFrame(\n",
    "        1 - pairwise_distances(movie_genomes_df.values, movie_genomes_df.values, metric='cosine'), index=all_movies,\n",
    "        columns=all_movies)\n",
    "    diversity_of_list = intra_list_distances_df.sum(axis=1).sum() * (1 / (N_size * (N_size - 1)))\n",
    "    similarity_of_list = 1 - diversity_of_list\n",
    "\n",
    "    average_similarity = model_pairwise_scores_df['similarity'].mean()\n",
    "    average_diversity = model_pairwise_scores_df['diversity'].mean()\n",
    "\n",
    "    print(\"diversity_of_list: \", diversity_of_list)\n",
    "    print(\"similarity_of_list: \", similarity_of_list)\n",
    "    print(\"average_diversity: \", average_diversity)\n",
    "    print(\"average_similarity: \", average_similarity)\n",
    "\n",
    "    return diversity_of_list, similarity_of_list, average_diversity, average_similarity\n",
    "\n",
    "\n",
    "def evaluate_all_models(experimental_users_list, result_dict, N_recommendations):\n",
    "    for user_id in experimental_users_list:\n",
    "        for model in result_dict:\n",
    "            evaluation_result = evaluate_recommendations(user_id, main_model_lemmatized, N_recommendations, movie_lemmatized_genome_scores_df,\n",
    "                                     user_lemmatized_genome_vector_df)\n",
    "\n",
    "\n",
    "def update_recommendation_results_dict(recommendation_results_dict, recommendation_list, key):\n",
    "    previous_recommendations_list = recommendation_results_dict[key.name]\n",
    "    previous_recommendations_list.append(recommendation_list)\n",
    "    recommendation_results_dict[key.name] = previous_recommendations_list\n",
    "\n",
    "\n",
    "class Model(Enum):\n",
    "    main_model_lemmatized = 'main_model_lemmatized'\n",
    "    main_model_full = 'main_model_full'\n",
    "    baseline_genre_binary = 'baseline_genre_binary'\n",
    "    baseline_genre_int = 'baseline_genre_int'\n",
    "    baseline_genome_lemmatized = 'baseline_genome_lemmatized'\n",
    "    baseline_genome_full = 'baseline_genome_full'\n",
    "\n",
    "\n",
    "def get_vector_type(baseline_model):\n",
    "    model_to_vector_dict = {\n",
    "        Model.baseline_genre_binary: BaselineRecommender_VectorType.GENRE_BINARY,\n",
    "        Model.baseline_genre_int: BaselineRecommender_VectorType.GENRE_INTEGER,\n",
    "        Model.baseline_genome_lemmatized: BaselineRecommender_VectorType.GENOME_LEMMATIZED,\n",
    "        Model.baseline_genome_full: BaselineRecommender_VectorType.GENOME_FULL\n",
    "    }\n",
    "\n",
    "    return model_to_vector_dict[baseline_model]\n",
    "\n",
    "\n",
    "# def main():\n",
    "dataset = 'ml20m'\n",
    "data_loader = DataLoaderPreprocessor(base_dir=base_dir, ml20m='ml-20m/',\n",
    "                                     serendipity2018='serendipity-sac2018/')\n",
    "ratings_df, genome_scores_df, movies_df = data_loader.load_and_preprocess_data(dataset)\n",
    "\n",
    "movie_genre_binary_terms_df, movies_lemmatized_genome_term_vector_df, \\\n",
    "user_int_genre_terms_df, user_genre_binary_term_vector_df, user_lemmatized_genome_terms_df, user_full_genome_terms_df \\\n",
    "    = data_loader.load_and_process_user_data(dataset)\n",
    "\n",
    "# movie_genre_binary_terms_df, movies_genome_term_vector_df, user_int_genre_terms_df,\\\n",
    "# user_lemmatized_genome_terms_df, user_full_genome_terms_df \\\n",
    "\n",
    "user_id = 1\n",
    "K = 20\n",
    "\n",
    "recommendation_results_dict = {\n",
    "    'main_model_lemmatized': list(),\n",
    "    'main_model_full': list(),\n",
    "    'baseline_genre_binary': list(),\n",
    "    'baseline_genre_int': list(),\n",
    "    'baseline_genome_lemmatized': list(),\n",
    "    'baseline_genome_full': list()\n",
    "}\n",
    "\n",
    "baseline_models = [Model.baseline_genre_binary, Model.baseline_genre_int, Model.baseline_genome_lemmatized,\n",
    "                   Model.baseline_genome_full]\n",
    "\n",
    "experimental_users_list = range(1, 20)\n",
    "experimental_users_list = [9, 10, 11, 12, 13, 14]\n",
    "\n",
    "for user_id in experimental_users_list:\n",
    "    item_terms = movies_lemmatized_genome_term_vector_df.values\n",
    "    item_item_distances = pairwise_distances(item_terms, metric='cosine')\n",
    "    item_item_similarity_df = pd.DataFrame(item_item_distances, index=movies_lemmatized_genome_term_vector_df.index,\n",
    "                                           columns=movies_lemmatized_genome_term_vector_df.index)\n",
    "\n",
    "    recommender_lemmatized = CB_ClusteringBased_Recommender(ratings_df, movies_lemmatized_genome_term_vector_df,\n",
    "                                                            user_lemmatized_genome_terms_df,\n",
    "                                                            item_item_similarity_df)\n",
    "\n",
    "    recommended_movies = recommender_lemmatized.recommend_movies(user_id, K=K)\n",
    "\n",
    "    # update recommendations for this user\n",
    "    update_recommendation_results_dict(recommendation_results_dict, recommended_movies,\n",
    "                                       key=Model.main_model_lemmatized)\n",
    "\n",
    "    print(\"\\nMain Model Lemmatized results:\\n\", recommended_movies)\n",
    "\n",
    "    item_terms = genome_scores_df.values\n",
    "    item_item_distances = pairwise_distances(item_terms, metric='cosine')\n",
    "    item_item_similarity_df = pd.DataFrame(item_item_distances, index=genome_scores_df.index,\n",
    "                                           columns=genome_scores_df.index)\n",
    "\n",
    "    recommender_full = CB_ClusteringBased_Recommender(ratings_df, genome_scores_df,\n",
    "                                                      user_full_genome_terms_df,\n",
    "                                                      item_item_similarity_df)\n",
    "\n",
    "    recommended_movies = recommender_full.recommend_movies(user_id, K=K)\n",
    "\n",
    "    # update recommendations for this user\n",
    "    update_recommendation_results_dict(recommendation_results_dict, recommended_movies,\n",
    "                                       key=Model.main_model_full)\n",
    "\n",
    "    print(\"\\nMain Model full-genome results:\\n\", recommended_movies)\n",
    "\n",
    "    # vector_type = BaselineRecommender_VectorType.GENOME_FULL\n",
    "\n",
    "    # arr = ['genre_binary:\\n', 'genre_integer:\\n', 'genome_lemmatized:\\n', 'genome_full:\\n']\n",
    "\n",
    "    for baseline_model in baseline_models:\n",
    "        vector_type = get_vector_type(baseline_model)\n",
    "\n",
    "        # baseline_recommender = ContentBased_Baseline_Recommender(dataset):\n",
    "        baseline_recommender = ContentBased_Baseline_Recommender(dataset, movie_genre_binary_terms_df,\n",
    "                                                                 movies_lemmatized_genome_term_vector_df,\n",
    "                                                                 user_int_genre_terms_df,\n",
    "                                                                 user_genre_binary_term_vector_df,\n",
    "                                                                 user_lemmatized_genome_terms_df,\n",
    "                                                                 user_full_genome_terms_df, ratings_df,\n",
    "                                                                 genome_scores_df, movies_df)\n",
    "        recommended_movies = baseline_recommender.recommend_k_most_similar_movies(user_id, K, vector_type=vector_type)\n",
    "        # print(arr[vector_type - 1], result)\n",
    "        update_recommendation_results_dict(recommendation_results_dict, recommended_movies,\n",
    "                                           key=baseline_model)\n",
    "\n",
    "print(\"experimental_users_list: \", experimental_users_list)\n",
    "print(\"recommendation_results_dict dictionary:\\n\", recommendation_results_dict)\n",
    "\n",
    "# evaluate all models and produce results\n",
    "evaluate_all_models(experimental_users_list, recommendation_results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'main_model_lemmatized': [[6132,\n",
       "   64037,\n",
       "   112091,\n",
       "   5891,\n",
       "   50189,\n",
       "   96691,\n",
       "   6036,\n",
       "   6775,\n",
       "   5781,\n",
       "   1862,\n",
       "   559,\n",
       "   3472,\n",
       "   113345,\n",
       "   4982,\n",
       "   74154,\n",
       "   6599,\n",
       "   112091,\n",
       "   34150,\n",
       "   109189,\n",
       "   8785],\n",
       "  [8675,\n",
       "   33750,\n",
       "   8608,\n",
       "   5919,\n",
       "   108778,\n",
       "   104441,\n",
       "   64037,\n",
       "   85367,\n",
       "   45635,\n",
       "   81751,\n",
       "   5363,\n",
       "   27564,\n",
       "   72407,\n",
       "   101281,\n",
       "   6550,\n",
       "   108981,\n",
       "   108727,\n",
       "   1116,\n",
       "   97744,\n",
       "   3272],\n",
       "  [106072,\n",
       "   70336,\n",
       "   6564,\n",
       "   72378,\n",
       "   5781,\n",
       "   63,\n",
       "   3472,\n",
       "   559,\n",
       "   44193,\n",
       "   59022,\n",
       "   96691,\n",
       "   1862,\n",
       "   50189,\n",
       "   6036,\n",
       "   112091,\n",
       "   113345,\n",
       "   92264,\n",
       "   2557,\n",
       "   5153,\n",
       "   7439],\n",
       "  [1939,\n",
       "   1936,\n",
       "   1933,\n",
       "   3808,\n",
       "   96691,\n",
       "   113345,\n",
       "   5781,\n",
       "   3472,\n",
       "   108778,\n",
       "   559,\n",
       "   1862,\n",
       "   112091,\n",
       "   69526,\n",
       "   44193,\n",
       "   6036,\n",
       "   112370,\n",
       "   50189,\n",
       "   86835,\n",
       "   80363,\n",
       "   3847],\n",
       "  [1939,\n",
       "   1936,\n",
       "   1933,\n",
       "   3808,\n",
       "   5781,\n",
       "   44193,\n",
       "   108778,\n",
       "   3472,\n",
       "   559,\n",
       "   1862,\n",
       "   3847,\n",
       "   96691,\n",
       "   113345,\n",
       "   50189,\n",
       "   6036,\n",
       "   112091,\n",
       "   63992,\n",
       "   92264,\n",
       "   64037,\n",
       "   95543],\n",
       "  [31030,\n",
       "   51638,\n",
       "   1939,\n",
       "   1936,\n",
       "   3847,\n",
       "   3472,\n",
       "   80363,\n",
       "   64037,\n",
       "   108778,\n",
       "   5781,\n",
       "   559,\n",
       "   50189,\n",
       "   6550,\n",
       "   1862,\n",
       "   69526,\n",
       "   108727,\n",
       "   3216,\n",
       "   113345,\n",
       "   78467,\n",
       "   87520]],\n",
       " 'main_model_full': [[64037,\n",
       "   6132,\n",
       "   4752,\n",
       "   4645,\n",
       "   96691,\n",
       "   44193,\n",
       "   6775,\n",
       "   3472,\n",
       "   6144,\n",
       "   80860,\n",
       "   39441,\n",
       "   701,\n",
       "   4069,\n",
       "   6041,\n",
       "   48600,\n",
       "   49286,\n",
       "   56949,\n",
       "   88950,\n",
       "   8785,\n",
       "   2632],\n",
       "  [80363,\n",
       "   72407,\n",
       "   108778,\n",
       "   33815,\n",
       "   5363,\n",
       "   55232,\n",
       "   5157,\n",
       "   66639,\n",
       "   6748,\n",
       "   5717,\n",
       "   81751,\n",
       "   5189],\n",
       "  [113345,\n",
       "   106072,\n",
       "   27618,\n",
       "   102125,\n",
       "   3472,\n",
       "   44193,\n",
       "   96691,\n",
       "   4069,\n",
       "   4887,\n",
       "   113345,\n",
       "   27664,\n",
       "   102072,\n",
       "   108778,\n",
       "   66639,\n",
       "   92264,\n",
       "   86835,\n",
       "   559,\n",
       "   8142,\n",
       "   36519,\n",
       "   95543],\n",
       "  [64114,\n",
       "   6450,\n",
       "   111249,\n",
       "   94018,\n",
       "   96691,\n",
       "   108778,\n",
       "   44193,\n",
       "   3472,\n",
       "   69526,\n",
       "   559,\n",
       "   113345,\n",
       "   86835,\n",
       "   102072,\n",
       "   6775,\n",
       "   66639,\n",
       "   112370,\n",
       "   127298,\n",
       "   5351,\n",
       "   27664,\n",
       "   3216],\n",
       "  [6264,\n",
       "   101076,\n",
       "   87520,\n",
       "   27618,\n",
       "   108778,\n",
       "   44193,\n",
       "   3472,\n",
       "   4069,\n",
       "   559,\n",
       "   96691,\n",
       "   102072,\n",
       "   66639,\n",
       "   3216,\n",
       "   5351,\n",
       "   92264,\n",
       "   64037,\n",
       "   5620,\n",
       "   86835,\n",
       "   8911,\n",
       "   27664],\n",
       "  [4310,\n",
       "   102072,\n",
       "   3472,\n",
       "   44193,\n",
       "   3847,\n",
       "   92206,\n",
       "   108778,\n",
       "   69526,\n",
       "   5951,\n",
       "   3216,\n",
       "   5269,\n",
       "   8785]],\n",
       " 'baseline_genre_binary': [[127206,\n",
       "   50,\n",
       "   904,\n",
       "   750,\n",
       "   1212,\n",
       "   1198,\n",
       "   3030,\n",
       "   100553,\n",
       "   1284,\n",
       "   5618,\n",
       "   1252,\n",
       "   1260,\n",
       "   260,\n",
       "   1196,\n",
       "   913,\n",
       "   2571,\n",
       "   950,\n",
       "   1248,\n",
       "   1148,\n",
       "   4226],\n",
       "  [3037,\n",
       "   7210,\n",
       "   4329,\n",
       "   82459,\n",
       "   2921,\n",
       "   3074,\n",
       "   2401,\n",
       "   6429,\n",
       "   3311,\n",
       "   5440,\n",
       "   8334,\n",
       "   3487,\n",
       "   5435,\n",
       "   6617,\n",
       "   31485,\n",
       "   25938,\n",
       "   6409,\n",
       "   44168,\n",
       "   6356,\n",
       "   5199],\n",
       "  [100553,\n",
       "   913,\n",
       "   1147,\n",
       "   1189,\n",
       "   120478,\n",
       "   2066,\n",
       "   1361,\n",
       "   3077,\n",
       "   8228,\n",
       "   3677,\n",
       "   246,\n",
       "   58425,\n",
       "   85774,\n",
       "   7566,\n",
       "   1258,\n",
       "   602,\n",
       "   162,\n",
       "   96606,\n",
       "   80906,\n",
       "   7096],\n",
       "  [100553,\n",
       "   913,\n",
       "   1147,\n",
       "   1189,\n",
       "   120478,\n",
       "   2066,\n",
       "   1361,\n",
       "   3077,\n",
       "   8228,\n",
       "   3677,\n",
       "   246,\n",
       "   58425,\n",
       "   85774,\n",
       "   7566,\n",
       "   602,\n",
       "   162,\n",
       "   96606,\n",
       "   80906,\n",
       "   7096,\n",
       "   114635],\n",
       "  [100553,\n",
       "   1284,\n",
       "   913,\n",
       "   1147,\n",
       "   1189,\n",
       "   2859,\n",
       "   120478,\n",
       "   2066,\n",
       "   942,\n",
       "   2726,\n",
       "   1361,\n",
       "   3077,\n",
       "   8228,\n",
       "   3677,\n",
       "   246,\n",
       "   58425,\n",
       "   85774,\n",
       "   7566,\n",
       "   602,\n",
       "   162],\n",
       "  [2066,\n",
       "   4426,\n",
       "   7335,\n",
       "   5169,\n",
       "   746,\n",
       "   3292,\n",
       "   1154,\n",
       "   1153,\n",
       "   3380,\n",
       "   5795,\n",
       "   72090,\n",
       "   91697,\n",
       "   99444,\n",
       "   110510,\n",
       "   913,\n",
       "   2726,\n",
       "   4432,\n",
       "   5017,\n",
       "   2612,\n",
       "   7943]],\n",
       " 'baseline_genre_int': [[127206,\n",
       "   50,\n",
       "   904,\n",
       "   750,\n",
       "   1212,\n",
       "   1198,\n",
       "   3030,\n",
       "   100553,\n",
       "   1284,\n",
       "   5618,\n",
       "   1252,\n",
       "   1260,\n",
       "   260,\n",
       "   1196,\n",
       "   913,\n",
       "   2571,\n",
       "   950,\n",
       "   1248,\n",
       "   1148,\n",
       "   4226],\n",
       "  [3037,\n",
       "   7210,\n",
       "   4329,\n",
       "   82459,\n",
       "   2921,\n",
       "   3074,\n",
       "   2401,\n",
       "   6429,\n",
       "   3311,\n",
       "   5440,\n",
       "   8334,\n",
       "   3487,\n",
       "   5435,\n",
       "   6617,\n",
       "   31485,\n",
       "   25938,\n",
       "   6409,\n",
       "   44168,\n",
       "   6356,\n",
       "   5199],\n",
       "  [100553,\n",
       "   913,\n",
       "   1147,\n",
       "   1189,\n",
       "   120478,\n",
       "   2066,\n",
       "   1361,\n",
       "   3077,\n",
       "   8228,\n",
       "   3677,\n",
       "   246,\n",
       "   58425,\n",
       "   85774,\n",
       "   7566,\n",
       "   1258,\n",
       "   602,\n",
       "   162,\n",
       "   96606,\n",
       "   80906,\n",
       "   7096],\n",
       "  [100553,\n",
       "   913,\n",
       "   1147,\n",
       "   1189,\n",
       "   120478,\n",
       "   2066,\n",
       "   1361,\n",
       "   3077,\n",
       "   8228,\n",
       "   3677,\n",
       "   246,\n",
       "   58425,\n",
       "   85774,\n",
       "   7566,\n",
       "   602,\n",
       "   162,\n",
       "   96606,\n",
       "   80906,\n",
       "   7096,\n",
       "   114635],\n",
       "  [100553,\n",
       "   1284,\n",
       "   913,\n",
       "   1147,\n",
       "   1189,\n",
       "   2859,\n",
       "   120478,\n",
       "   2066,\n",
       "   942,\n",
       "   2726,\n",
       "   1361,\n",
       "   3077,\n",
       "   8228,\n",
       "   3677,\n",
       "   246,\n",
       "   58425,\n",
       "   85774,\n",
       "   7566,\n",
       "   602,\n",
       "   162],\n",
       "  [2066,\n",
       "   4426,\n",
       "   7335,\n",
       "   5169,\n",
       "   746,\n",
       "   3292,\n",
       "   1154,\n",
       "   1153,\n",
       "   3380,\n",
       "   5795,\n",
       "   72090,\n",
       "   91697,\n",
       "   99444,\n",
       "   110510,\n",
       "   3037,\n",
       "   7210,\n",
       "   4329,\n",
       "   82459,\n",
       "   2921,\n",
       "   3074]],\n",
       " 'baseline_genome_lemmatized': [[4271,\n",
       "   5687,\n",
       "   6107,\n",
       "   33750,\n",
       "   1315,\n",
       "   77833,\n",
       "   50619,\n",
       "   31702,\n",
       "   2933,\n",
       "   2669,\n",
       "   6818,\n",
       "   26246,\n",
       "   101207,\n",
       "   26231,\n",
       "   3670,\n",
       "   5794,\n",
       "   58876,\n",
       "   1534,\n",
       "   5614,\n",
       "   6123],\n",
       "  [115414,\n",
       "   74075,\n",
       "   104312,\n",
       "   110809,\n",
       "   73106,\n",
       "   3216,\n",
       "   3804,\n",
       "   39421,\n",
       "   59429,\n",
       "   92938,\n",
       "   3691,\n",
       "   53464,\n",
       "   6036,\n",
       "   87430,\n",
       "   559,\n",
       "   77414,\n",
       "   4974,\n",
       "   51077,\n",
       "   7317,\n",
       "   2894],\n",
       "  [1315,\n",
       "   4271,\n",
       "   5687,\n",
       "   50619,\n",
       "   3216,\n",
       "   26231,\n",
       "   6107,\n",
       "   33750,\n",
       "   77833,\n",
       "   4872,\n",
       "   2933,\n",
       "   31702,\n",
       "   6818,\n",
       "   26241,\n",
       "   1534,\n",
       "   5794,\n",
       "   2669,\n",
       "   108778,\n",
       "   26246,\n",
       "   27114],\n",
       "  [3216,\n",
       "   26231,\n",
       "   26241,\n",
       "   1315,\n",
       "   50619,\n",
       "   4872,\n",
       "   2894,\n",
       "   108981,\n",
       "   559,\n",
       "   5687,\n",
       "   7024,\n",
       "   4271,\n",
       "   5351,\n",
       "   5794,\n",
       "   3804,\n",
       "   7976,\n",
       "   6036,\n",
       "   3621,\n",
       "   69134,\n",
       "   110809],\n",
       "  [3216,\n",
       "   26231,\n",
       "   26241,\n",
       "   4271,\n",
       "   50619,\n",
       "   1315,\n",
       "   5687,\n",
       "   2894,\n",
       "   559,\n",
       "   108981,\n",
       "   7024,\n",
       "   4872,\n",
       "   5794,\n",
       "   5351,\n",
       "   3472,\n",
       "   3621,\n",
       "   3804,\n",
       "   69134,\n",
       "   4752,\n",
       "   6036],\n",
       "  [3216,\n",
       "   26241,\n",
       "   64037,\n",
       "   5891,\n",
       "   2894,\n",
       "   26231,\n",
       "   559,\n",
       "   4752,\n",
       "   7024,\n",
       "   108981,\n",
       "   4872,\n",
       "   3804,\n",
       "   5569,\n",
       "   7976,\n",
       "   6132,\n",
       "   3272,\n",
       "   69134,\n",
       "   1315,\n",
       "   3472,\n",
       "   495]],\n",
       " 'baseline_genome_full': [[5687,\n",
       "   1315,\n",
       "   1534,\n",
       "   2933,\n",
       "   4271,\n",
       "   5614,\n",
       "   3242,\n",
       "   50619,\n",
       "   5351,\n",
       "   2632,\n",
       "   787,\n",
       "   3687,\n",
       "   26743,\n",
       "   33750,\n",
       "   6160,\n",
       "   6123,\n",
       "   4237,\n",
       "   33124,\n",
       "   4347,\n",
       "   6107],\n",
       "  [104312,\n",
       "   115414,\n",
       "   74075,\n",
       "   77414,\n",
       "   110809,\n",
       "   97785,\n",
       "   43930,\n",
       "   3216,\n",
       "   5413,\n",
       "   5687,\n",
       "   96691,\n",
       "   1315,\n",
       "   54734,\n",
       "   63393,\n",
       "   80363,\n",
       "   3687,\n",
       "   39421,\n",
       "   88108,\n",
       "   5351,\n",
       "   73106],\n",
       "  [5687,\n",
       "   1315,\n",
       "   1534,\n",
       "   2933,\n",
       "   4271,\n",
       "   50619,\n",
       "   5614,\n",
       "   27114,\n",
       "   4884,\n",
       "   5351,\n",
       "   2632,\n",
       "   5473,\n",
       "   3216,\n",
       "   3242,\n",
       "   787,\n",
       "   47274,\n",
       "   33124,\n",
       "   33750,\n",
       "   6599,\n",
       "   4237],\n",
       "  [5687,\n",
       "   1315,\n",
       "   5351,\n",
       "   3216,\n",
       "   1534,\n",
       "   4271,\n",
       "   50619,\n",
       "   2632,\n",
       "   2933,\n",
       "   4752,\n",
       "   3242,\n",
       "   3621,\n",
       "   5413,\n",
       "   4884,\n",
       "   3472,\n",
       "   26231,\n",
       "   7024,\n",
       "   5473,\n",
       "   872,\n",
       "   26241],\n",
       "  [5687,\n",
       "   1315,\n",
       "   4271,\n",
       "   5351,\n",
       "   3216,\n",
       "   1534,\n",
       "   2632,\n",
       "   50619,\n",
       "   2933,\n",
       "   5413,\n",
       "   3242,\n",
       "   3621,\n",
       "   4752,\n",
       "   3472,\n",
       "   872,\n",
       "   26231,\n",
       "   26241,\n",
       "   5794,\n",
       "   4884,\n",
       "   7024],\n",
       "  [4752,\n",
       "   5413,\n",
       "   5687,\n",
       "   3216,\n",
       "   6132,\n",
       "   5891,\n",
       "   5717,\n",
       "   8906,\n",
       "   1315,\n",
       "   7024,\n",
       "   3621,\n",
       "   3472,\n",
       "   5351,\n",
       "   5569,\n",
       "   3652,\n",
       "   4271,\n",
       "   96691,\n",
       "   4884,\n",
       "   3344,\n",
       "   1534]]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experimental_users_list\n",
    "recommendation_results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_genome_df_dict = {\n",
    "    Model.main_model_lemmatized: (movies_lemmatized_genome_term_vector_df, user_lemmatized_genome_terms_df),\n",
    "    Model.main_model_full: (genome_scores_df, user_full_genome_terms_df),\n",
    "    Model.baseline_genre_binary: (genome_scores_df, user_full_genome_terms_df),\n",
    "    Model.baseline_genre_int: (genome_scores_df, user_full_genome_terms_df),\n",
    "    Model.baseline_genome_full: (genome_scores_df, user_full_genome_terms_df),\n",
    "    Model.baseline_genome_lemmatized: (genome_scores_df, user_full_genome_terms_df)\n",
    "}\n",
    "\n",
    "def map_movie_user_terms_df(model):\n",
    "    model = Model(model)\n",
    "    \n",
    "    return model_to_genome_df_dict[model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------Model:  main_model_lemmatized -------------------\n",
      "diversity_of_list:  0.6538389817053769\n",
      "similarity_of_list:  0.3461610182946231\n",
      "average_diversity:  0.7458426117017684\n",
      "average_similarity:  0.2541573882982318\n",
      "(0.6538389817053769, 0.3461610182946231, 0.7458426117017684, 0.2541573882982318)\n",
      "userId                                    9\n",
      "model                 main_model_lemmatized\n",
      "diversity_of_list                  0.653839\n",
      "similarity_of_list                 0.346161\n",
      "average_diversity                  0.745843\n",
      "average_similarity                 0.254157\n",
      "Name: 1, dtype: object\n",
      "diversity_of_list:  0.6562736415154014\n",
      "similarity_of_list:  0.34372635848459865\n",
      "average_diversity:  0.6594873448824956\n",
      "average_similarity:  0.3405126551175045\n",
      "(0.6562736415154014, 0.34372635848459865, 0.6594873448824956, 0.3405126551175045)\n",
      "userId                                   10\n",
      "model                 main_model_lemmatized\n",
      "diversity_of_list                  0.656274\n",
      "similarity_of_list                 0.343726\n",
      "average_diversity                  0.659487\n",
      "average_similarity                 0.340513\n",
      "Name: 2, dtype: object\n",
      "diversity_of_list:  0.6872938401880313\n",
      "similarity_of_list:  0.3127061598119687\n",
      "average_diversity:  0.7592582002793385\n",
      "average_similarity:  0.2407417997206615\n",
      "(0.6872938401880313, 0.3127061598119687, 0.7592582002793385, 0.2407417997206615)\n",
      "userId                                   11\n",
      "model                 main_model_lemmatized\n",
      "diversity_of_list                  0.687294\n",
      "similarity_of_list                 0.312706\n",
      "average_diversity                  0.759258\n",
      "average_similarity                 0.240742\n",
      "Name: 3, dtype: object\n",
      "diversity_of_list:  0.6396728965138675\n",
      "similarity_of_list:  0.3603271034861325\n",
      "average_diversity:  0.7164150070797918\n",
      "average_similarity:  0.2835849929202082\n",
      "(0.6396728965138675, 0.3603271034861325, 0.7164150070797918, 0.2835849929202082)\n",
      "userId                                   12\n",
      "model                 main_model_lemmatized\n",
      "diversity_of_list                  0.639673\n",
      "similarity_of_list                 0.360327\n",
      "average_diversity                  0.716415\n",
      "average_similarity                 0.283585\n",
      "Name: 4, dtype: object\n",
      "diversity_of_list:  0.6312331978602973\n",
      "similarity_of_list:  0.3687668021397027\n",
      "average_diversity:  0.715126843811319\n",
      "average_similarity:  0.2848731561886811\n",
      "(0.6312331978602973, 0.3687668021397027, 0.715126843811319, 0.2848731561886811)\n",
      "userId                                   13\n",
      "model                 main_model_lemmatized\n",
      "diversity_of_list                  0.631233\n",
      "similarity_of_list                 0.368767\n",
      "average_diversity                  0.715127\n",
      "average_similarity                 0.284873\n",
      "Name: 5, dtype: object\n",
      "diversity_of_list:  0.637151081380054\n",
      "similarity_of_list:  0.36284891861994595\n",
      "average_diversity:  0.6941227642257778\n",
      "average_similarity:  0.30587723577422216\n",
      "(0.637151081380054, 0.36284891861994595, 0.6941227642257778, 0.30587723577422216)\n",
      "userId                                   14\n",
      "model                 main_model_lemmatized\n",
      "diversity_of_list                  0.637151\n",
      "similarity_of_list                 0.362849\n",
      "average_diversity                  0.694123\n",
      "average_similarity                 0.305877\n",
      "Name: 6, dtype: object\n",
      "\n",
      "-------------------Model:  main_model_full -------------------\n",
      "diversity_of_list:  0.5286674320264754\n",
      "similarity_of_list:  0.47133256797352463\n",
      "average_diversity:  0.6429123090988096\n",
      "average_similarity:  0.3570876909011903\n",
      "(0.5286674320264754, 0.47133256797352463, 0.6429123090988096, 0.3570876909011903)\n",
      "userId                              9\n",
      "model                 main_model_full\n",
      "diversity_of_list            0.528667\n",
      "similarity_of_list           0.471333\n",
      "average_diversity            0.642912\n",
      "average_similarity           0.357088\n",
      "Name: 7, dtype: object\n",
      "diversity_of_list:  0.20644730289100585\n",
      "similarity_of_list:  0.7935526971089941\n",
      "average_diversity:  0.5710340368718098\n",
      "average_similarity:  0.42896596312819013\n",
      "(0.20644730289100585, 0.7935526971089941, 0.5710340368718098, 0.42896596312819013)\n",
      "userId                             10\n",
      "model                 main_model_full\n",
      "diversity_of_list            0.206447\n",
      "similarity_of_list           0.793553\n",
      "average_diversity            0.571034\n",
      "average_similarity           0.428966\n",
      "Name: 8, dtype: object\n",
      "diversity_of_list:  0.5865614348393497\n",
      "similarity_of_list:  0.41343856516065025\n",
      "average_diversity:  0.7006451812874787\n",
      "average_similarity:  0.2993548187125214\n",
      "(0.5865614348393497, 0.41343856516065025, 0.7006451812874787, 0.2993548187125214)\n",
      "userId                             11\n",
      "model                 main_model_full\n",
      "diversity_of_list            0.586561\n",
      "similarity_of_list           0.413439\n",
      "average_diversity            0.700645\n",
      "average_similarity           0.299355\n",
      "Name: 9, dtype: object\n",
      "diversity_of_list:  0.5319367924627397\n",
      "similarity_of_list:  0.4680632075372603\n",
      "average_diversity:  0.6294307687881899\n",
      "average_similarity:  0.37056923121181007\n",
      "(0.5319367924627397, 0.4680632075372603, 0.6294307687881899, 0.37056923121181007)\n",
      "userId                             12\n",
      "model                 main_model_full\n",
      "diversity_of_list            0.531937\n",
      "similarity_of_list           0.468063\n",
      "average_diversity            0.629431\n",
      "average_similarity           0.370569\n",
      "Name: 10, dtype: object\n",
      "diversity_of_list:  0.557019910393619\n",
      "similarity_of_list:  0.442980089606381\n",
      "average_diversity:  0.6387893649621375\n",
      "average_similarity:  0.36121063503786266\n",
      "(0.557019910393619, 0.442980089606381, 0.6387893649621375, 0.36121063503786266)\n",
      "userId                             13\n",
      "model                 main_model_full\n",
      "diversity_of_list             0.55702\n",
      "similarity_of_list            0.44298\n",
      "average_diversity            0.638789\n",
      "average_similarity           0.361211\n",
      "Name: 11, dtype: object\n",
      "diversity_of_list:  0.20312426840102016\n",
      "similarity_of_list:  0.7968757315989798\n",
      "average_diversity:  0.6092780499264201\n",
      "average_similarity:  0.3907219500735799\n",
      "(0.20312426840102016, 0.7968757315989798, 0.6092780499264201, 0.3907219500735799)\n",
      "userId                             14\n",
      "model                 main_model_full\n",
      "diversity_of_list            0.203124\n",
      "similarity_of_list           0.796876\n",
      "average_diversity            0.609278\n",
      "average_similarity           0.390722\n",
      "Name: 12, dtype: object\n",
      "\n",
      "-------------------Model:  baseline_genre_binary -------------------\n",
      "diversity_of_list:  0.8164379675144636\n",
      "similarity_of_list:  0.18356203248553637\n",
      "average_diversity:  0.7780436737209235\n",
      "average_similarity:  0.22195632627907638\n",
      "(0.8164379675144636, 0.18356203248553637, 0.7780436737209235, 0.22195632627907638)\n",
      "userId                                    9\n",
      "model                 baseline_genre_binary\n",
      "diversity_of_list                  0.816438\n",
      "similarity_of_list                 0.183562\n",
      "average_diversity                  0.778044\n",
      "average_similarity                 0.221956\n",
      "Name: 13, dtype: object\n",
      "diversity_of_list:  0.9039753946555165\n",
      "similarity_of_list:  0.09602460534448354\n",
      "average_diversity:  0.852983212138262\n",
      "average_similarity:  0.1470167878617379\n",
      "(0.9039753946555165, 0.09602460534448354, 0.852983212138262, 0.1470167878617379)\n",
      "userId                                   10\n",
      "model                 baseline_genre_binary\n",
      "diversity_of_list                  0.903975\n",
      "similarity_of_list                0.0960246\n",
      "average_diversity                  0.852983\n",
      "average_similarity                 0.147017\n",
      "Name: 14, dtype: object\n",
      "diversity_of_list:  0.8224055537991326\n",
      "similarity_of_list:  0.1775944462008674\n",
      "average_diversity:  0.7366323699214337\n",
      "average_similarity:  0.26336763007856645\n",
      "(0.8224055537991326, 0.1775944462008674, 0.7366323699214337, 0.26336763007856645)\n",
      "userId                                   11\n",
      "model                 baseline_genre_binary\n",
      "diversity_of_list                  0.822406\n",
      "similarity_of_list                 0.177594\n",
      "average_diversity                  0.736632\n",
      "average_similarity                 0.263368\n",
      "Name: 15, dtype: object\n",
      "diversity_of_list:  0.8272316345313317\n",
      "similarity_of_list:  0.17276836546866825\n",
      "average_diversity:  0.7416155443949092\n",
      "average_similarity:  0.2583844556050908\n",
      "(0.8272316345313317, 0.17276836546866825, 0.7416155443949092, 0.2583844556050908)\n",
      "userId                                   12\n",
      "model                 baseline_genre_binary\n",
      "diversity_of_list                  0.827232\n",
      "similarity_of_list                 0.172768\n",
      "average_diversity                  0.741616\n",
      "average_similarity                 0.258384\n",
      "Name: 16, dtype: object\n",
      "diversity_of_list:  0.8315141323149104\n",
      "similarity_of_list:  0.16848586768508955\n",
      "average_diversity:  0.7576381257872363\n",
      "average_similarity:  0.24236187421276373\n",
      "(0.8315141323149104, 0.16848586768508955, 0.7576381257872363, 0.24236187421276373)\n",
      "userId                                   13\n",
      "model                 baseline_genre_binary\n",
      "diversity_of_list                  0.831514\n",
      "similarity_of_list                 0.168486\n",
      "average_diversity                  0.757638\n",
      "average_similarity                 0.242362\n",
      "Name: 17, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-481977982f29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mmovie_terms_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_terms_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_movie_user_terms_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m#         if user_id is 14 and model is 'baseline_genre_binary':\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mevaluation_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_recommendations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecommendation_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_recommendations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovie_terms_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_terms_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mevaluation_results_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mappend_evaluation_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluation_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluation_results_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseries_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-d591c2ab8580>\u001b[0m in \u001b[0;36mevaluate_recommendations\u001b[0;34m(user_id, recommendation_list, N_size, movie_genome_scores_df, user_genome_terms_df)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mmodel_pairwise_scores_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecommendation_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     model_pairwise_scores_df['similarity'] = pairwise_distances(user_vector_df, movie_genomes_df.values,\n\u001b[0;32m---> 27\u001b[0;31m                                                                 metric='cosine').reshape(-1, 1)\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mmodel_pairwise_scores_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'diversity'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmodel_pairwise_scores_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'similarity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1430\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1432\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1067\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \u001b[0;31m# TODO: in some cases, backend='threading' may be appropriate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_distances\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m    548\u001b[0m     \"\"\"\n\u001b[1;32m    549\u001b[0m     \u001b[0;31m# 1.0 - cosine_similarity(X, Y) without copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m     \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m     \u001b[0mS\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0mS\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m    894\u001b[0m     \u001b[0;31m# to avoid recursive import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0mX_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype)\u001b[0m\n\u001b[1;32m    111\u001b[0m                         warn_on_dtype=warn_on_dtype, estimator=estimator)\n\u001b[1;32m    112\u001b[0m         Y = check_array(Y, accept_sparse='csr', dtype=dtype,\n\u001b[0;32m--> 113\u001b[0;31m                         warn_on_dtype=warn_on_dtype, estimator=estimator)\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprecomputed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 573\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# this code will go under evaluate_all_models method\n",
    "\n",
    "# TODO remove from actual code\n",
    "N_recommendations = 20\n",
    "\n",
    "def append_evaluation_result(user_id, model, evaluation_result, evaluation_results_df, series_count):\n",
    "    result_dict = {\n",
    "        'userId' : user_id,\n",
    "        'model': model,\n",
    "        'diversity_of_list': evaluation_result[0],\n",
    "        'similarity_of_list': evaluation_result[1],\n",
    "        'average_diversity': evaluation_result[2],\n",
    "        'average_similarity': evaluation_result[3]\n",
    "    }\n",
    "    \n",
    "    result_ser = pd.Series(result_dict, name=series_count)\n",
    "    \n",
    "    print(result_ser)\n",
    "    \n",
    "    return evaluation_results_df.append(result_ser, ignore_index=False)\n",
    "\n",
    "# DF - user, model, evaluation scores\n",
    "evaluation_results_df = pd.DataFrame(columns=['userId', 'model', 'diversity_of_list', 'similarity_of_list', 'average_diversity', 'average_similarity'])\n",
    "series_count = 1\n",
    "\n",
    "for model in recommendation_results_dict.keys():\n",
    "    print('\\n-------------------Model: ', model, '-------------------')\n",
    "    for index, user_id in enumerate(experimental_users_list):\n",
    "        recommendation_list = recommendation_results_dict[model][index]\n",
    "#         print(\"\\nUser ID: \", user_id, 'RL: ', recommendation_list)\n",
    "#         user_id, recommendation_list, N_size, movie_genome_scores_df, user_genome_terms_df\n",
    "        \n",
    "        movie_terms_df, user_terms_df = map_movie_user_terms_df(model)\n",
    "#         if user_id is 14 and model is 'baseline_genre_binary':\n",
    "        evaluation_result = evaluate_recommendations(user_id, recommendation_list, N_recommendations, movie_terms_df, user_terms_df)\n",
    "        print(evaluation_result)\n",
    "        evaluation_results_df = append_evaluation_result(user_id, model, evaluation_result, evaluation_results_df, series_count)\n",
    "        series_count += 1\n",
    "\n",
    "evaluation_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>model</th>\n",
       "      <th>diversity_of_list</th>\n",
       "      <th>similarity_of_list</th>\n",
       "      <th>average_diversity</th>\n",
       "      <th>average_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>main_model_lemmatized</td>\n",
       "      <td>0.653839</td>\n",
       "      <td>0.346161</td>\n",
       "      <td>0.745843</td>\n",
       "      <td>0.254157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>main_model_lemmatized</td>\n",
       "      <td>0.656274</td>\n",
       "      <td>0.343726</td>\n",
       "      <td>0.659487</td>\n",
       "      <td>0.340513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>main_model_lemmatized</td>\n",
       "      <td>0.687294</td>\n",
       "      <td>0.312706</td>\n",
       "      <td>0.759258</td>\n",
       "      <td>0.240742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>main_model_lemmatized</td>\n",
       "      <td>0.639673</td>\n",
       "      <td>0.360327</td>\n",
       "      <td>0.716415</td>\n",
       "      <td>0.283585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13</td>\n",
       "      <td>main_model_lemmatized</td>\n",
       "      <td>0.631233</td>\n",
       "      <td>0.368767</td>\n",
       "      <td>0.715127</td>\n",
       "      <td>0.284873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14</td>\n",
       "      <td>main_model_lemmatized</td>\n",
       "      <td>0.637151</td>\n",
       "      <td>0.362849</td>\n",
       "      <td>0.694123</td>\n",
       "      <td>0.305877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>main_model_full</td>\n",
       "      <td>0.528667</td>\n",
       "      <td>0.471333</td>\n",
       "      <td>0.642912</td>\n",
       "      <td>0.357088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>main_model_full</td>\n",
       "      <td>0.206447</td>\n",
       "      <td>0.793553</td>\n",
       "      <td>0.571034</td>\n",
       "      <td>0.428966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>main_model_full</td>\n",
       "      <td>0.586561</td>\n",
       "      <td>0.413439</td>\n",
       "      <td>0.700645</td>\n",
       "      <td>0.299355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>main_model_full</td>\n",
       "      <td>0.531937</td>\n",
       "      <td>0.468063</td>\n",
       "      <td>0.629431</td>\n",
       "      <td>0.370569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>main_model_full</td>\n",
       "      <td>0.557020</td>\n",
       "      <td>0.442980</td>\n",
       "      <td>0.638789</td>\n",
       "      <td>0.361211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>main_model_full</td>\n",
       "      <td>0.203124</td>\n",
       "      <td>0.796876</td>\n",
       "      <td>0.609278</td>\n",
       "      <td>0.390722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9</td>\n",
       "      <td>baseline_genre_binary</td>\n",
       "      <td>0.816438</td>\n",
       "      <td>0.183562</td>\n",
       "      <td>0.778044</td>\n",
       "      <td>0.221956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10</td>\n",
       "      <td>baseline_genre_binary</td>\n",
       "      <td>0.903975</td>\n",
       "      <td>0.096025</td>\n",
       "      <td>0.852983</td>\n",
       "      <td>0.147017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11</td>\n",
       "      <td>baseline_genre_binary</td>\n",
       "      <td>0.822406</td>\n",
       "      <td>0.177594</td>\n",
       "      <td>0.736632</td>\n",
       "      <td>0.263368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>12</td>\n",
       "      <td>baseline_genre_binary</td>\n",
       "      <td>0.827232</td>\n",
       "      <td>0.172768</td>\n",
       "      <td>0.741616</td>\n",
       "      <td>0.258384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>13</td>\n",
       "      <td>baseline_genre_binary</td>\n",
       "      <td>0.831514</td>\n",
       "      <td>0.168486</td>\n",
       "      <td>0.757638</td>\n",
       "      <td>0.242362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId                  model  diversity_of_list  similarity_of_list  \\\n",
       "1       9  main_model_lemmatized           0.653839            0.346161   \n",
       "2      10  main_model_lemmatized           0.656274            0.343726   \n",
       "3      11  main_model_lemmatized           0.687294            0.312706   \n",
       "4      12  main_model_lemmatized           0.639673            0.360327   \n",
       "5      13  main_model_lemmatized           0.631233            0.368767   \n",
       "6      14  main_model_lemmatized           0.637151            0.362849   \n",
       "7       9        main_model_full           0.528667            0.471333   \n",
       "8      10        main_model_full           0.206447            0.793553   \n",
       "9      11        main_model_full           0.586561            0.413439   \n",
       "10     12        main_model_full           0.531937            0.468063   \n",
       "11     13        main_model_full           0.557020            0.442980   \n",
       "12     14        main_model_full           0.203124            0.796876   \n",
       "13      9  baseline_genre_binary           0.816438            0.183562   \n",
       "14     10  baseline_genre_binary           0.903975            0.096025   \n",
       "15     11  baseline_genre_binary           0.822406            0.177594   \n",
       "16     12  baseline_genre_binary           0.827232            0.172768   \n",
       "17     13  baseline_genre_binary           0.831514            0.168486   \n",
       "\n",
       "    average_diversity  average_similarity  \n",
       "1            0.745843            0.254157  \n",
       "2            0.659487            0.340513  \n",
       "3            0.759258            0.240742  \n",
       "4            0.716415            0.283585  \n",
       "5            0.715127            0.284873  \n",
       "6            0.694123            0.305877  \n",
       "7            0.642912            0.357088  \n",
       "8            0.571034            0.428966  \n",
       "9            0.700645            0.299355  \n",
       "10           0.629431            0.370569  \n",
       "11           0.638789            0.361211  \n",
       "12           0.609278            0.390722  \n",
       "13           0.778044            0.221956  \n",
       "14           0.852983            0.147017  \n",
       "15           0.736632            0.263368  \n",
       "16           0.741616            0.258384  \n",
       "17           0.757638            0.242362  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model('main_model_lemmatized')\n",
    "# size = evaluation_results_df.shape[0]\n",
    "# evaluation_results_df.set_index(list(range(1, size + 1)), drop=True, inplace=True)\n",
    "evaluation_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>diversity_of_list</th>\n",
       "      <th>similarity_of_list</th>\n",
       "      <th>average_diversity</th>\n",
       "      <th>average_similarity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">9</th>\n",
       "      <th>baseline_genre_binary</th>\n",
       "      <td>0.816438</td>\n",
       "      <td>0.183562</td>\n",
       "      <td>0.778044</td>\n",
       "      <td>0.221956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>main_model_full</th>\n",
       "      <td>0.528667</td>\n",
       "      <td>0.471333</td>\n",
       "      <td>0.642912</td>\n",
       "      <td>0.357088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>main_model_lemmatized</th>\n",
       "      <td>0.653839</td>\n",
       "      <td>0.346161</td>\n",
       "      <td>0.745843</td>\n",
       "      <td>0.254157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">10</th>\n",
       "      <th>baseline_genre_binary</th>\n",
       "      <td>0.903975</td>\n",
       "      <td>0.096025</td>\n",
       "      <td>0.852983</td>\n",
       "      <td>0.147017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>main_model_full</th>\n",
       "      <td>0.206447</td>\n",
       "      <td>0.793553</td>\n",
       "      <td>0.571034</td>\n",
       "      <td>0.428966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>main_model_lemmatized</th>\n",
       "      <td>0.656274</td>\n",
       "      <td>0.343726</td>\n",
       "      <td>0.659487</td>\n",
       "      <td>0.340513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">11</th>\n",
       "      <th>baseline_genre_binary</th>\n",
       "      <td>0.822406</td>\n",
       "      <td>0.177594</td>\n",
       "      <td>0.736632</td>\n",
       "      <td>0.263368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>main_model_full</th>\n",
       "      <td>0.586561</td>\n",
       "      <td>0.413439</td>\n",
       "      <td>0.700645</td>\n",
       "      <td>0.299355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>main_model_lemmatized</th>\n",
       "      <td>0.687294</td>\n",
       "      <td>0.312706</td>\n",
       "      <td>0.759258</td>\n",
       "      <td>0.240742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">12</th>\n",
       "      <th>baseline_genre_binary</th>\n",
       "      <td>0.827232</td>\n",
       "      <td>0.172768</td>\n",
       "      <td>0.741616</td>\n",
       "      <td>0.258384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>main_model_full</th>\n",
       "      <td>0.531937</td>\n",
       "      <td>0.468063</td>\n",
       "      <td>0.629431</td>\n",
       "      <td>0.370569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>main_model_lemmatized</th>\n",
       "      <td>0.639673</td>\n",
       "      <td>0.360327</td>\n",
       "      <td>0.716415</td>\n",
       "      <td>0.283585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">13</th>\n",
       "      <th>baseline_genre_binary</th>\n",
       "      <td>0.831514</td>\n",
       "      <td>0.168486</td>\n",
       "      <td>0.757638</td>\n",
       "      <td>0.242362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>main_model_full</th>\n",
       "      <td>0.557020</td>\n",
       "      <td>0.442980</td>\n",
       "      <td>0.638789</td>\n",
       "      <td>0.361211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>main_model_lemmatized</th>\n",
       "      <td>0.631233</td>\n",
       "      <td>0.368767</td>\n",
       "      <td>0.715127</td>\n",
       "      <td>0.284873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">14</th>\n",
       "      <th>main_model_full</th>\n",
       "      <td>0.203124</td>\n",
       "      <td>0.796876</td>\n",
       "      <td>0.609278</td>\n",
       "      <td>0.390722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>main_model_lemmatized</th>\n",
       "      <td>0.637151</td>\n",
       "      <td>0.362849</td>\n",
       "      <td>0.694123</td>\n",
       "      <td>0.305877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              diversity_of_list  similarity_of_list  \\\n",
       "userId model                                                          \n",
       "9      baseline_genre_binary           0.816438            0.183562   \n",
       "       main_model_full                 0.528667            0.471333   \n",
       "       main_model_lemmatized           0.653839            0.346161   \n",
       "10     baseline_genre_binary           0.903975            0.096025   \n",
       "       main_model_full                 0.206447            0.793553   \n",
       "       main_model_lemmatized           0.656274            0.343726   \n",
       "11     baseline_genre_binary           0.822406            0.177594   \n",
       "       main_model_full                 0.586561            0.413439   \n",
       "       main_model_lemmatized           0.687294            0.312706   \n",
       "12     baseline_genre_binary           0.827232            0.172768   \n",
       "       main_model_full                 0.531937            0.468063   \n",
       "       main_model_lemmatized           0.639673            0.360327   \n",
       "13     baseline_genre_binary           0.831514            0.168486   \n",
       "       main_model_full                 0.557020            0.442980   \n",
       "       main_model_lemmatized           0.631233            0.368767   \n",
       "14     main_model_full                 0.203124            0.796876   \n",
       "       main_model_lemmatized           0.637151            0.362849   \n",
       "\n",
       "                              average_diversity  average_similarity  \n",
       "userId model                                                         \n",
       "9      baseline_genre_binary           0.778044            0.221956  \n",
       "       main_model_full                 0.642912            0.357088  \n",
       "       main_model_lemmatized           0.745843            0.254157  \n",
       "10     baseline_genre_binary           0.852983            0.147017  \n",
       "       main_model_full                 0.571034            0.428966  \n",
       "       main_model_lemmatized           0.659487            0.340513  \n",
       "11     baseline_genre_binary           0.736632            0.263368  \n",
       "       main_model_full                 0.700645            0.299355  \n",
       "       main_model_lemmatized           0.759258            0.240742  \n",
       "12     baseline_genre_binary           0.741616            0.258384  \n",
       "       main_model_full                 0.629431            0.370569  \n",
       "       main_model_lemmatized           0.716415            0.283585  \n",
       "13     baseline_genre_binary           0.757638            0.242362  \n",
       "       main_model_full                 0.638789            0.361211  \n",
       "       main_model_lemmatized           0.715127            0.284873  \n",
       "14     main_model_full                 0.609278            0.390722  \n",
       "       main_model_lemmatized           0.694123            0.305877  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_result_df = evaluation_results_df.groupby(['userId', 'model']).mean()\n",
    "combined_result_df\n",
    "# evaluation_results_df.loc[:, 'diversity_of_list']\n",
    "# evaluation_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "combined_result_df.groupby('model').mean().plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recommendations = [1,2,3,4,5]\n",
    "user_ids = [10, 11]\n",
    "\n",
    "user_recommendations_df = pd.DataFrame()\n",
    "user_recommendations_df.index.name = 'user_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0    1    2    3    4\n",
       "user_id                         \n",
       "10       1.0  2.0  3.0  4.0  5.0\n",
       "11       1.0  2.0  3.0  4.0  5.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for user in user_ids:\n",
    "    user_rec_series = pd.Series(recommendations)\n",
    "    user_rec_series.name = user\n",
    "    \n",
    "    user_recommendations_df = user_recommendations_df.append(user_rec_series)\n",
    "    \n",
    "user_recommendations_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
