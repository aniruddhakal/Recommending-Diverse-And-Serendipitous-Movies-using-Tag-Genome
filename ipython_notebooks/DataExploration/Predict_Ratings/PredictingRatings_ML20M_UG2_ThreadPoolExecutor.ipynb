{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34763\n",
      "34545\n",
      "69462\n",
      "34486\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "import warnings\n",
    "import sys\n",
    "from sklearn.metrics import pairwise_distances, mean_absolute_error, mean_squared_error\n",
    "import multiprocessing as mp\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "\n",
    "import threading\n",
    "\n",
    "data_base_dir = '../../../../datasets/Movielens/'\n",
    "data_dir2 = data_base_dir + 'serendipity-sac2018/'\n",
    "data_dir = data_base_dir + 'ml-20m/'\n",
    "output_dir = data_dir + 'output2/'\n",
    "\n",
    "genome_scores = data_dir + 'genome-scores.csv'\n",
    "# genome_scores = data_dir + 'tag_genome.csv'\n",
    "genome_tags = data_dir + 'genome-tags.csv'\n",
    "movies = data_dir + 'movies.csv'\n",
    "ratings = data_dir + 'ratings.csv'\n",
    "# ratings = data_dir + 'training.csv'\n",
    "tags = data_dir + 'tags.csv'\n",
    "# answers = data_dir + 'answers.csv'\n",
    "genre_binary_terms = output_dir + 'movie_genre_binary_term_vector_df_bz2'\n",
    "movies_lemmatized = output_dir + 'movies_lemmatized_genome_vector_df_bz2'\n",
    "\n",
    "# data loading and preprocessing\n",
    "target_df = pd.read_csv(genome_scores).pivot(index='movieId', columns='tagId',\n",
    "                                             values='relevance')\n",
    "genome_scores_df = pd.DataFrame(pairwise_distances(target_df, metric='cosine'),\n",
    "                                index=target_df.index,\n",
    "                                columns=target_df.index)\n",
    "del target_df\n",
    "\n",
    "movies_with_genome = genome_scores_df.index.values\n",
    "\n",
    "movies_df = pd.read_csv(movies)\n",
    "movies_df = movies_df[movies_df['genres'] != '(no genres listed)']\n",
    "movies_df = movies_df[movies_df['movieId'].isin(movies_with_genome)]\n",
    "del movies_with_genome\n",
    "\n",
    "all_movie_ids = movies_df['movieId'].unique()\n",
    "del movies_df\n",
    "\n",
    "ratings_df = pd.read_csv(ratings)\n",
    "ratings_df = ratings_df[ratings_df['movieId'].isin(all_movie_ids)]\n",
    "ratings_df = ratings_df.loc[:, ['userId', 'movieId', 'rating']]\n",
    "\n",
    "all_user_ids = ratings_df['userId'].unique()\n",
    "\n",
    "\n",
    "class ContentBased_Recommender:\n",
    "    def __init__(self, term_vector_df, ratings_df, K=5, metric='cosine', weighted=True):\n",
    "        self.term_vector_df = term_vector_df\n",
    "        self.K = K\n",
    "        self.ratings_df = ratings_df\n",
    "        self.weighted = weighted\n",
    "\n",
    "        # preprocessing and other calculations\n",
    "        self.term_vector_df.fillna(0, inplace=True)\n",
    "        self.movie_movie_distances = term_vector_df\n",
    "\n",
    "    def get_mae_mse(self, user_id, candidate_movie_id, user_movies, K):\n",
    "        # movies watched by user\n",
    "        #         if user_movies is None:\n",
    "        #             user_movies = ratings_df[ratings_df['userId'] == user_id]['movieId'].values\n",
    "\n",
    "        # hide candidate movie from the user\n",
    "        user_movies = np.setdiff1d(user_movies, candidate_movie_id)\n",
    "\n",
    "        # load user rating for watched movies other than the candidate movie\n",
    "        # user_ratings =\n",
    "        users_all_ratings_df = ratings_df[ratings_df['userId'] == user_id]\n",
    "        users_all_ratings_df = users_all_ratings_df[\n",
    "            users_all_ratings_df['movieId'].isin(user_movies)]\n",
    "\n",
    "        # load similarities to the candidate movie\n",
    "        users_all_ratings_df['sim_candidate_movie'] = self.movie_movie_distances.loc[\n",
    "            candidate_movie_id, users_all_ratings_df['movieId']].values\n",
    "\n",
    "        mae, mse = self.predict_ratings_and_get_mae_mse(user_id, candidate_movie_id,\n",
    "                                                        users_all_ratings_df, K)\n",
    "\n",
    "        return mae, mse\n",
    "\n",
    "    def predict_ratings_and_get_mae_mse(self, user_id, candidate_movie_id, users_all_ratings_df,\n",
    "                                        K):\n",
    "        user_ratings = users_all_ratings_df['rating'].values[:K]\n",
    "        similarities = users_all_ratings_df['sim_candidate_movie'].values[:K]\n",
    "\n",
    "        predicted_rating = 0\n",
    "        if self.weighted:\n",
    "            # weighted average\n",
    "            predicted_rating = np.sum(user_ratings * similarities) / np.sum(similarities)\n",
    "        else:\n",
    "            # non-weighted average\n",
    "            predicted_rating = np.sum(user_ratings) / len(user_ratings)\n",
    "\n",
    "        actual_rating = self.ratings_df[(self.ratings_df['userId'] == user_id) & (\n",
    "                self.ratings_df['movieId'] == candidate_movie_id)]['rating'].values[0]\n",
    "\n",
    "        if np.isnan(predicted_rating):\n",
    "            #             predicted_rating = 0\n",
    "            predicted_rating = actual_rating\n",
    "\n",
    "        mae = mean_absolute_error([actual_rating], [predicted_rating])\n",
    "        mse = mean_squared_error([actual_rating], [predicted_rating])\n",
    "\n",
    "        return mae, mse\n",
    "\n",
    "    def get_average_mae_mse(self, user_id, user_movies, K):\n",
    "        # movies watched by user\n",
    "        #         if user_movies is None:\n",
    "        #             user_movies = ratings_df[ratings_df['userId'] == user_id]['movieId'].values\n",
    "        mae_list = list()\n",
    "        mse_list = list()\n",
    "\n",
    "        for candidate_movie_id in user_movies:\n",
    "            mae, mse = self.get_mae_mse(user_id, candidate_movie_id, user_movies, K)\n",
    "\n",
    "            mae_list.append(mae)\n",
    "            mse_list.append(mse)\n",
    "\n",
    "        return np.median(np.array(mae_list)), np.median(np.array(mse_list))\n",
    "\n",
    "\n",
    "l1 = 'movies_lemmatized_threshold_'\n",
    "l2 = '_float_movie_genomes_bz2'\n",
    "\n",
    "# threshold_0.2_float_movie_genomes_bz2\n",
    "l3 = 'threshold_'\n",
    "l4 = '_float_movie_genomes_bz2'\n",
    "\n",
    "thresholds = [0.25, 0.4, 0.7]\n",
    "# thresholds = [0.25]\n",
    "\n",
    "lemmatized_labels = [(l1 + str(x) + l2) for x in thresholds]\n",
    "\n",
    "full_labels = [(l3 + str(x) + l4) for x in thresholds]\n",
    "\n",
    "lemmatized_thresholded_dfs = list()\n",
    "full_thresholded_dfs = list()\n",
    "\n",
    "metric = 'cosine'\n",
    "\n",
    "for i, t in enumerate(thresholds):\n",
    "    target_df = pd.read_pickle(output_dir + lemmatized_labels[i], compression='bz2')\n",
    "    distances_df = pd.DataFrame(pairwise_distances(target_df, metric=metric), index=target_df.index,\n",
    "                                columns=target_df.index)\n",
    "    del target_df\n",
    "    lemmatized_thresholded_dfs.append(distances_df)\n",
    "\n",
    "    target_df = pd.read_pickle(output_dir + full_labels[i], compression='bz2')\n",
    "    distances_df = pd.DataFrame(pairwise_distances(target_df, metric=metric), index=target_df.index,\n",
    "                                columns=target_df.index)\n",
    "    del target_df\n",
    "    full_thresholded_dfs.append(distances_df)\n",
    "\n",
    "# load term vectors\n",
    "target_df = pd.read_pickle(genre_binary_terms, compression='bz2')\n",
    "genre_binary_terms_df = pd.DataFrame(pairwise_distances(target_df, metric=metric),\n",
    "                                     index=target_df.index,\n",
    "                                     columns=target_df.index)\n",
    "del target_df\n",
    "\n",
    "target_df = pd.read_pickle(movies_lemmatized, compression='bz2')\n",
    "movies_lemmatized_df = pd.DataFrame(pairwise_distances(target_df, metric=metric),\n",
    "                                    index=target_df.index,\n",
    "                                    columns=target_df.index)\n",
    "del target_df\n",
    "\n",
    "global_user_id = 0\n",
    "\n",
    "\n",
    "def update_global_uid(uid):\n",
    "    global_user_id = uid\n",
    "\n",
    "\n",
    "count_df = ratings_df.groupby('userId').count()\n",
    "# count_df.describe()\n",
    "\n",
    "# # divide user groups into 4 based on the number of movies watched by them\n",
    "threshold1 = count_df['movieId'] <= 34\n",
    "threshold2 = count_df['movieId'] <= 67\n",
    "threshold3 = count_df['movieId'] <= 154\n",
    "threshold4 = count_df['movieId'] > 154\n",
    "\n",
    "user_group_1 = count_df[threshold1].index.values\n",
    "user_group_2 = count_df[threshold2].index.values\n",
    "user_group_3 = count_df[threshold3].index.values\n",
    "user_group_4 = count_df[threshold4].index.values\n",
    "\n",
    "del count_df\n",
    "\n",
    "user_group_2 = np.setdiff1d(user_group_2, user_group_1)\n",
    "user_group_3 = np.setdiff1d(user_group_3, user_group_2)\n",
    "user_group_4 = np.setdiff1d(user_group_4, user_group_3)\n",
    "\n",
    "print(user_group_1.size)\n",
    "print(user_group_2.size)\n",
    "print(user_group_3.size)\n",
    "print(user_group_4.size)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "labels = ['genre_binary', 'genome_full', 'genome_lemmatized']\n",
    "all_movie_ids = genre_binary_terms_df.index.values\n",
    "\n",
    "#     for index, K in enumerate(K_ranges):\n",
    "genre_recommender = ContentBased_Recommender(genre_binary_terms_df, ratings_df,\n",
    "                                             metric='jaccard', weighted=True)\n",
    "genome_full_recommender = ContentBased_Recommender(genome_scores_df, ratings_df,\n",
    "                                                   metric='cosine', weighted=True)\n",
    "genome_lemmatized_recommender = ContentBased_Recommender(movies_lemmatized_df, ratings_df,\n",
    "                                                         metric='cosine', weighted=True)\n",
    "\n",
    "lemmatized_recommenders = list()\n",
    "full_recommenders = list()\n",
    "\n",
    "for i, t in enumerate(thresholds):\n",
    "    full_recommenders.append(\n",
    "        ContentBased_Recommender(full_thresholded_dfs[i], ratings_df, weighted=True))\n",
    "    lemmatized_recommenders.append(\n",
    "        ContentBased_Recommender(lemmatized_thresholded_dfs[i], ratings_df,\n",
    "                                 weighted=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunPredictions:\n",
    "\n",
    "    def run(this, K, UG, users_ndarray, start_range=0, end_range=None):\n",
    "        print('running for K: %d' % K)\n",
    "        if end_range is None:\n",
    "            end_range = len(users_ndarray)\n",
    "\n",
    "        # mae lists\n",
    "        genre_mae_list = list()\n",
    "        genome_full_mae_list = list()\n",
    "        genome_lemmatized_mae_list = list()\n",
    "\n",
    "        lemmatized_mae_list = list()\n",
    "        full_mae_list = list()\n",
    "\n",
    "        # mse lists\n",
    "        genre_mse_list = list()\n",
    "        genome_full_mse_list = list()\n",
    "        genome_lemmatized_mse_list = list()\n",
    "\n",
    "        lemmatized_mse_list = list()\n",
    "        full_mse_list = list()\n",
    "\n",
    "        for user_id in users_ndarray[start_range:end_range]:\n",
    "            start_time = time()\n",
    "            update_global_uid(user_id)\n",
    "            print('user_id', user_id)\n",
    "\n",
    "            # movies watched by user\n",
    "            user_movies = ratings_df[ratings_df['userId'] == user_id]['movieId'].values\n",
    "\n",
    "            if len(user_movies) <= 1:\n",
    "                continue\n",
    "\n",
    "            mae, mse = genre_recommender.get_average_mae_mse(user_id, user_movies, K)\n",
    "            genre_mae_list.append(mae)\n",
    "            genre_mse_list.append(mse)\n",
    "\n",
    "            mae, mse = genome_full_recommender.get_average_mae_mse(user_id, user_movies, K)\n",
    "            genome_full_mae_list.append(mae)\n",
    "            genome_full_mse_list.append(mse)\n",
    "\n",
    "            mae, mse = genome_lemmatized_recommender.get_average_mae_mse(user_id, user_movies, K)\n",
    "            genome_lemmatized_mae_list.append(mae)\n",
    "            genome_lemmatized_mse_list.append(mse)\n",
    "\n",
    "            for i, t in enumerate(thresholds):\n",
    "                mae, mse = full_recommenders[i].get_average_mae_mse(user_id, user_movies, K)\n",
    "                full_mae_list.append(mae)\n",
    "                full_mse_list.append(mse)\n",
    "\n",
    "                mae, mse = lemmatized_recommenders[i].get_average_mae_mse(user_id, user_movies, K)\n",
    "                lemmatized_mae_list.append(mae)\n",
    "                lemmatized_mse_list.append(mse)\n",
    "\n",
    "            finish_time = time() - start_time\n",
    "            print(\"Total time taken for this user: %f seconds\" % finish_time)\n",
    "\n",
    "        mae_df = pd.DataFrame()\n",
    "        mae_df['genre_MAE'] = genre_mae_list\n",
    "        mae_df['genome_full_MAE'] = genome_full_mae_list\n",
    "        mae_df['genome_lemmatized_MAE'] = genome_lemmatized_mae_list\n",
    "\n",
    "        mse_df = pd.DataFrame()\n",
    "        mse_df['genre_MSE'] = genre_mse_list\n",
    "        mse_df['genome_full_MSE'] = genome_full_mse_list\n",
    "        mse_df['genome_lemmatized_MSE'] = genome_lemmatized_mse_list\n",
    "\n",
    "        for i, t in enumerate(thresholds):\n",
    "            mae_df[full_labels[i] + '_MAE'] = full_mae_list[i]\n",
    "            mse_df[full_labels[i] + '_MSE'] = full_mse_list[i]\n",
    "\n",
    "            mae_df[lemmatized_labels[i] + '_MAE'] = lemmatized_mae_list[i]\n",
    "            mse_df[lemmatized_labels[i] + '_MSE'] = lemmatized_mse_list[i]\n",
    "\n",
    "        mae_df.median().plot(kind='barh',\n",
    "                             title='K=' + str(K) + ', median MAE, ' + UG, figsize=(11, 5))\n",
    "        figname = output_dir + 'K=' + str(K) + ', median MAE, ' + UG\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(fname=figname, dpi=150)\n",
    "\n",
    "        mse_df.median().plot(kind='barh',\n",
    "                             title='K=' + str(K) + ', median MSE, ' + UG, figsize=(11, 5))\n",
    "\n",
    "        figname = output_dir + 'K=' + str(K) + ', median MAE, ' + UG\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(fname=figname, dpi=150)\n",
    "\n",
    "\n",
    "def run_parallel_for_users_range(UG, users_ndarray, K_ranges, start_range, end_range):\n",
    "    with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "        for index, K in enumerate(K_ranges):\n",
    "            rp = RunPredictions()\n",
    "            executor.submit(rp.run, K, UG, users_ndarray, start_range, end_range)\n",
    "            \n",
    "    print(\"main thread\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing main method...\n",
      "running for K: 5\n",
      "running for K: 10\n",
      "user_id 2\n",
      "user_id 2\n",
      "Total time taken for this user: 67.129819 seconds\n",
      "user_id 5\n",
      "Total time taken for this user: 67.287606 seconds\n",
      "user_id 5\n",
      "Total time taken for this user: 78.206669 seconds\n",
      "Total time taken for this user: 78.249028 seconds\n",
      "main thread\n"
     ]
    }
   ],
   "source": [
    "print(\"executing main method...\")\n",
    "# K_ranges = [5, 10, 15, 20]\n",
    "K_ranges = [5, 10]\n",
    "start_range = 0\n",
    "# end_range = len(all_answers_user_ids)\n",
    "end_range = 2\n",
    "\n",
    "UG = 'UG2'\n",
    "run_parallel_for_users_range(UG, user_group_2, K_ranges, start_range, end_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
