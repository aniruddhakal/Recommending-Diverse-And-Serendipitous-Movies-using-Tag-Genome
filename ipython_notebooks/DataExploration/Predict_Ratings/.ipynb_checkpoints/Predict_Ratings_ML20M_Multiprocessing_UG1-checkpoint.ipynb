{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_base_dir = '../../../../datasets/Movielens/'\n",
    "data_dir2 = data_base_dir + 'serendipity-sac2018/'\n",
    "data_dir = data_base_dir + 'ml-20m/'\n",
    "output_dir = data_dir + 'output/'\n",
    "\n",
    "genome_scores = data_dir + 'genome-scores.csv'\n",
    "# genome_scores = data_dir + 'tag_genome.csv'\n",
    "genome_tags = data_dir + 'genome-tags.csv'\n",
    "movies = data_dir + 'movies.csv'\n",
    "ratings = data_dir + 'ratings.csv'\n",
    "# ratings = data_dir + 'training.csv'\n",
    "tags = data_dir + 'tags.csv'\n",
    "# answers = data_dir + 'answers.csv'\n",
    "genre_binary_terms = output_dir + 'movie_genre_binary_term_vector_df_bz2'\n",
    "movies_lemmatized = output_dir + 'movies_lemmatized_genome_vector_df_bz2'\n",
    "\n",
    "# answers_df = pd.read_csv(answers)\n",
    "\n",
    "# data loading and preprocessing\n",
    "genome_scores_df = pd.read_csv(genome_scores).pivot(index='movieId', columns='tagId',\n",
    "                                                    values='relevance')\n",
    "movies_with_genome = genome_scores_df.index.values\n",
    "# movies_with_genome\n",
    "\n",
    "movies_df = pd.read_csv(movies)\n",
    "movies_df = movies_df[movies_df['genres'] != '(no genres listed)']\n",
    "movies_df = movies_df[movies_df['movieId'].isin(movies_with_genome)]\n",
    "\n",
    "all_movie_ids = movies_df['movieId'].unique()\n",
    "\n",
    "ratings_df = pd.read_csv(ratings)\n",
    "ratings_df = ratings_df[ratings_df['movieId'].isin(all_movie_ids)]\n",
    "ratings_df = ratings_df.loc[:, ['userId', 'movieId', 'rating']]\n",
    "\n",
    "all_user_ids = ratings_df['userId'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO also filter users only inside recommendations or answers dataframe\n",
    "# count_df = answers_df.groupby('userId').count()\n",
    "# count_df[count_df['movieId'] == 5]\n",
    "# all_answers_user_ids = count_df[count_df['movieId'] == 5].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances, mean_absolute_error, mean_squared_error\n",
    "\n",
    "\n",
    "class ContentBased_Recommender:\n",
    "    def __init__(self, term_vector_df, ratings_df, K=5, metric='cosine', weighted=True):\n",
    "        self.term_vector_df = term_vector_df\n",
    "        self.K = K\n",
    "        self.ratings_df = ratings_df\n",
    "        self.weighted = weighted\n",
    "\n",
    "        # preprocessing and other calculations\n",
    "        self.term_vector_df.fillna(0, inplace=True)\n",
    "        self.movie_movie_distances = pd.DataFrame(\n",
    "            pairwise_distances(self.term_vector_df, metric=metric), index=self.term_vector_df.index,\n",
    "            columns=self.term_vector_df.index)\n",
    "\n",
    "    def get_mae_mse(self, user_id, candidate_movie_id, user_movies):\n",
    "        # movies watched by user\n",
    "        #         if user_movies is None:\n",
    "        #             user_movies = ratings_df[ratings_df['userId'] == user_id]['movieId'].values\n",
    "\n",
    "        # hide candidate movie from the user\n",
    "        user_movies = np.setdiff1d(user_movies, candidate_movie_id)\n",
    "\n",
    "        # load user rating for watched movies other than the candidate movie\n",
    "        # user_ratings =\n",
    "        users_all_ratings_df = ratings_df[ratings_df['userId'] == user_id]\n",
    "        users_all_ratings_df = users_all_ratings_df[\n",
    "            users_all_ratings_df['movieId'].isin(user_movies)]\n",
    "\n",
    "        # load similarities to the candidate movie\n",
    "        users_all_ratings_df['sim_candidate_movie'] = self.movie_movie_distances.loc[\n",
    "            candidate_movie_id, users_all_ratings_df['movieId']].values\n",
    "\n",
    "        mae, mse = self.predict_ratings_and_get_mae_mse(user_id, candidate_movie_id,\n",
    "                                                        users_all_ratings_df)\n",
    "\n",
    "        return mae, mse\n",
    "\n",
    "    def predict_ratings_and_get_mae_mse(self, user_id, candidate_movie_id, users_all_ratings_df):\n",
    "        user_ratings = users_all_ratings_df['rating'].values[:self.K]\n",
    "        similarities = users_all_ratings_df['sim_candidate_movie'].values[:self.K]\n",
    "\n",
    "        predicted_rating = 0\n",
    "        if self.weighted:\n",
    "            # weighted average\n",
    "            predicted_rating = np.sum(user_ratings * similarities) / np.sum(similarities)\n",
    "        else:\n",
    "            # non-weighted average\n",
    "            predicted_rating = np.sum(user_ratings) / len(user_ratings)\n",
    "\n",
    "        actual_rating = self.ratings_df[(self.ratings_df['userId'] == user_id) & (\n",
    "                self.ratings_df['movieId'] == candidate_movie_id)]['rating'].values[0]\n",
    "\n",
    "        if np.isnan(predicted_rating):\n",
    "            #             predicted_rating = 0\n",
    "            predicted_rating = actual_rating\n",
    "\n",
    "        mae = mean_absolute_error([actual_rating], [predicted_rating])\n",
    "        mse = mean_squared_error([actual_rating], [predicted_rating])\n",
    "\n",
    "        return mae, mse\n",
    "\n",
    "    def get_average_mae_mse(self, user_id, user_movies):\n",
    "        # movies watched by user\n",
    "        #         if user_movies is None:\n",
    "        #             user_movies = ratings_df[ratings_df['userId'] == user_id]['movieId'].values\n",
    "\n",
    "        mae_list = list()\n",
    "        mse_list = list()\n",
    "\n",
    "        for candidate_movie_id in user_movies:\n",
    "            mae, mse = self.get_mae_mse(user_id, candidate_movie_id, user_movies)\n",
    "\n",
    "            mae_list.append(mae)\n",
    "            mse_list.append(mse)\n",
    "\n",
    "        return np.median(np.array(mae_list)), np.median(np.array(mse_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['threshold_0.25_float_movie_genomes_bz2',\n",
       " 'threshold_0.4_float_movie_genomes_bz2',\n",
       " 'threshold_0.7_float_movie_genomes_bz2']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = 'movies_lemmatized_threshold_'\n",
    "l2 = '_float_movie_genomes_bz2'\n",
    "\n",
    "# threshold_0.2_float_movie_genomes_bz2\n",
    "l3 = 'threshold_'\n",
    "l4 = '_float_movie_genomes_bz2'\n",
    "\n",
    "thresholds = [0.25, 0.4, 0.7]\n",
    "# thresholds = [0.25]\n",
    "\n",
    "lemmatized_labels = [(l1 + str(x) + l2) for x in thresholds]\n",
    "lemmatized_labels\n",
    "\n",
    "full_labels = [(l3 + str(x) + l4) for x in thresholds]\n",
    "full_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loading all required data\n",
    "# user_full_genome_terms_df = pd.read_pickle(output_dir + 'user_full_genome_terms_df_bz2',\n",
    "#                                            compression='bz2')\n",
    "# user_full_genome_terms_gzip_df = pd.read_pickle(output_dir + 'user_full_genome_terms_df_gzip',\n",
    "#                                                 compression='bz2')\n",
    "\n",
    "lemmatized_thresholded_dfs = list()\n",
    "full_thresholded_dfs = list()\n",
    "\n",
    "for i, t in enumerate(thresholds):\n",
    "    lemmatized_thresholded_dfs.append(\n",
    "        pd.read_pickle(output_dir + lemmatized_labels[i], compression='bz2'))\n",
    "    full_thresholded_dfs.append(\n",
    "        pd.read_pickle(output_dir + full_labels[i], compression='bz2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load term vectors\n",
    "genre_binary_terms_df = pd.read_pickle(genre_binary_terms, compression='bz2')\n",
    "movies_lemmatized_df = pd.read_pickle(movies_lemmatized, compression='bz2')\n",
    "global_user_id=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "labels = ['genre_binary', 'genome_full', 'genome_lemmatized']\n",
    "all_movie_ids = genre_binary_terms_df.index.values\n",
    "\n",
    "\n",
    "def run(index, K, start_range, end_range):\n",
    "    #     for index, K in enumerate(K_ranges):\n",
    "    genre_recommender = ContentBased_Recommender(genre_binary_terms_df, ratings_df, K,\n",
    "                                                 metric='jaccard', weighted=True)\n",
    "    genome_full_recommender = ContentBased_Recommender(genome_scores_df, ratings_df, K,\n",
    "                                                       metric='cosine', weighted=True)\n",
    "    genome_lemmatized_recommender = ContentBased_Recommender(movies_lemmatized_df, ratings_df, K,\n",
    "                                                             metric='cosine', weighted=True)\n",
    "\n",
    "    lemmatized_recommenders = list()\n",
    "    full_recommenders = list()\n",
    "\n",
    "    for i, t in enumerate(thresholds):\n",
    "        full_recommenders.append(\n",
    "            ContentBased_Recommender(full_thresholded_dfs[i], ratings_df, K, weighted=True))\n",
    "        lemmatized_recommenders.append(\n",
    "            ContentBased_Recommender(lemmatized_thresholded_dfs[i], ratings_df, K, weighted=True))\n",
    "\n",
    "    # mae lists\n",
    "    genre_mae_list = list()\n",
    "    genome_full_mae_list = list()\n",
    "    genome_lemmatized_mae_list = list()\n",
    "\n",
    "    lemmatized_mae_list = list()\n",
    "    full_mae_list = list()\n",
    "\n",
    "    # mse lists\n",
    "    genre_mse_list = list()\n",
    "    genome_full_mse_list = list()\n",
    "    genome_lemmatized_mse_list = list()\n",
    "\n",
    "    lemmatized_mse_list = list()\n",
    "    full_mse_list = list()\n",
    "\n",
    "    for user_id in all_user_ids[start_range:end_range]:\n",
    "        start_time = time()\n",
    "        global_user_id = user_id\n",
    "        print('user_id', user_id)\n",
    "\n",
    "        # movies watched by user\n",
    "        user_movies = ratings_df[ratings_df['userId'] == user_id]['movieId'].values\n",
    "\n",
    "        if len(user_movies) <= 1:\n",
    "            continue\n",
    "\n",
    "        mae, mse = genre_recommender.get_average_mae_mse(user_id, user_movies)\n",
    "        genre_mae_list.append(mae)\n",
    "        genre_mse_list.append(mse)\n",
    "\n",
    "        mae, mse = genome_full_recommender.get_average_mae_mse(user_id, user_movies)\n",
    "        genome_full_mae_list.append(mae)\n",
    "        genome_full_mse_list.append(mse)\n",
    "\n",
    "        mae, mse = genome_lemmatized_recommender.get_average_mae_mse(user_id, user_movies)\n",
    "        genome_lemmatized_mae_list.append(mae)\n",
    "        genome_lemmatized_mse_list.append(mse)\n",
    "\n",
    "        for i, t in enumerate(thresholds):\n",
    "            mae, mse = full_recommenders[i].get_average_mae_mse(user_id, user_movies)\n",
    "            full_mae_list.append(mae)\n",
    "            full_mse_list.append(mse)\n",
    "\n",
    "            mae, mse = lemmatized_recommenders[i].get_average_mae_mse(user_id, user_movies)\n",
    "            lemmatized_mae_list.append(mae)\n",
    "            lemmatized_mse_list.append(mse)\n",
    "\n",
    "        finish_time = time() - start_time\n",
    "        print(\"Total time taken for this user: %f seconds\" % finish_time)\n",
    "\n",
    "    mae_df = pd.DataFrame()\n",
    "    mae_df['genre_MAE'] = genre_mae_list\n",
    "    mae_df['genome_full_MAE'] = genome_full_mae_list\n",
    "    mae_df['genome_lemmatized_MAE'] = genome_lemmatized_mae_list\n",
    "\n",
    "    mse_df = pd.DataFrame()\n",
    "    mse_df['genre_MSE'] = genre_mse_list\n",
    "    mse_df['genome_full_MSE'] = genome_full_mse_list\n",
    "    mse_df['genome_lemmatized_MSE'] = genome_lemmatized_mse_list\n",
    "\n",
    "    for i, t in enumerate(thresholds):\n",
    "        mae_df[full_labels[i] + '_MAE'] = full_mae_list[i]\n",
    "        mse_df[full_labels[i] + '_MSE'] = full_mse_list[i]\n",
    "\n",
    "        mae_df[lemmatized_labels[i] + '_MAE'] = lemmatized_mae_list[i]\n",
    "        mse_df[lemmatized_labels[i] + '_MSE'] = lemmatized_mse_list[i]\n",
    "\n",
    "    print(\"\")\n",
    "    mae_df.median().plot(kind='barh',\n",
    "                         title='K=' + str(K) + ', avg MAE across all users, for all movies')\n",
    "    plt.show()\n",
    "    mse_df.median().plot(kind='barh',\n",
    "                         title='K=' + str(K) + ', avg MSE across all users, for all movies')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "import multiprocessing as mp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def run_parallel_for_users_range(start_range, end_range, K_ranges):\n",
    "    # K_ranges = [5, 10, 15, 20, 30, 40, 50]\n",
    "#     K_ranges = [5, 10, 15, 20]\n",
    "    # K_ranges = [5]\n",
    "\n",
    "#     start_range = 0\n",
    "#     end_range = len(all_answers_user_ids)\n",
    "\n",
    "    p_list = list()\n",
    "    for index, K in enumerate(K_ranges):\n",
    "        p = mp.Process(target=run, args=(index, K,start_range, end_range,))\n",
    "        p_list.append(p)\n",
    "        p.start()\n",
    "\n",
    "#     for p in p_list:\n",
    "#         # wait until all processes are finished\n",
    "#         p.join()\n",
    "\n",
    "    print(\"main process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34763\n",
      "34545\n",
      "69462\n",
      "34486\n"
     ]
    }
   ],
   "source": [
    "count_df = ratings_df.groupby('userId').count()\n",
    "# count_df\n",
    "# count_df.describe()\n",
    "# # divide user groups into 4 based on the number of movies watched by them\n",
    "threshold1 = count_df['movieId'] <= 34\n",
    "threshold2 = count_df['movieId'] <= 67\n",
    "threshold3 = count_df['movieId'] <= 154\n",
    "threshold4 = count_df['movieId'] > 154\n",
    "\n",
    "user_group_1 = count_df[threshold1].index.values\n",
    "user_group_2 = count_df[threshold2].index.values\n",
    "user_group_3 = count_df[threshold3].index.values\n",
    "user_group_4 = count_df[threshold4].index.values\n",
    "\n",
    "user_group_2 = np.setdiff1d(user_group_2, user_group_1)\n",
    "user_group_3 = np.setdiff1d(user_group_3, user_group_2)\n",
    "user_group_4 = np.setdiff1d(user_group_4, user_group_3)\n",
    "\n",
    "print(user_group_1.size)\n",
    "print(user_group_2.size)\n",
    "print(user_group_3.size)\n",
    "print(user_group_4.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-14:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-11-8b03df72cf99>\", line 14, in run\n",
      "    metric='jaccard', weighted=True)\n",
      "  File \"<ipython-input-3-0ca503217713>\", line 14, in __init__\n",
      "    pairwise_distances(self.term_vector_df, metric=metric), index=self.term_vector_df.index,\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/pairwise.py\", line 1429, in pairwise_distances\n",
      "    **kwds))\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/scipy/spatial/distance.py\", line 2159, in squareform\n",
      "    M = np.zeros((d, d), dtype=X.dtype)\n",
      "MemoryError\n"
     ]
    }
   ],
   "source": [
    "K_ranges = [5, 10, 15, 20]\n",
    "start_range = 0\n",
    "# end_range = len(all_answers_user_ids)\n",
    "end_range = 5\n",
    "run_parallel_for_users_range(start_range, end_range, K_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# user_id = 206808\n",
    "import sys\n",
    "\n",
    "# def print_progress():\n",
    "#     sys.stdout.write('\\rProgress %.2f%%' % ((np.where(user_group_1[:5] == global_user_id)[0][0]/(user_group_1[:5].size - 1)) * 100))\n",
    "#     sys.stdout.flush()\n",
    "    \n",
    "# p_list = list()\n",
    "# p = mp.Process(target=print_progress, args=())\n",
    "# p_list.append(p)\n",
    "# p.start()\n",
    "\n",
    "# #     for p in p_list:\n",
    "# #         # wait until all processes are finished\n",
    "# #         p.join()\n",
    "\n",
    "# print(\"main process\\n\")\n",
    "print(global_user_id)\n",
    "# np.where(user_group_1[:5] == global_user_id)\n",
    "# sys.stdout.write('\\rProgress %.2f%%' % ((np.where(user_group_1[:5] == global_user_id)[0][0]/(user_group_1[:5].size - 1)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": [
     "# %%\n",
     "import numpy as np\n",
     "import pandas as pd\n",
     "import matplotlib.pyplot as plt\n",
     "\n",
     "data_base_dir = '../../datasets/Movielens/'\n",
     "data_dir = data_base_dir + 'serendipity-sac2018/'\n",
     "data_dir2 = data_base_dir + 'ml-20m/'\n",
     "output_dir = data_dir + 'output/'\n",
     "\n",
     "# genome_scores = data_dir + 'genome_scores.csv'\n",
     "genome_scores = data_dir + 'tag_genome.csv'\n",
     "# genome_tags = data_dir + 'genome-tags.csv'\n",
     "movies = data_dir + 'movies.csv'\n",
     "# ratings = data_dir + 'ratings.csv'\n",
     "ratings = data_dir + 'training.csv'\n",
     "# tags = data_dir + 'tags.csv'\n",
     "answers = data_dir + 'answers.csv'\n",
     "genre_binary_terms = output_dir + 'movie_genre_binary_term_vector_df_bz2'\n",
     "movies_lemmatized = output_dir + 'movies_lemmatized_genome_vector_df_bz2'\n",
     "\n",
     "answers_df = pd.read_csv(answers)\n",
     "\n",
     "# data loading and preprocessing\n",
     "genome_scores_df = pd.read_csv(genome_scores).pivot(index='movieId', columns='tagId',\n",
     "                                                    values='relevance')\n",
     "movies_with_genome = genome_scores_df.index.values\n",
     "# movies_with_genome\n",
     "\n",
     "movies_df = pd.read_csv(movies)\n",
     "movies_df = movies_df[movies_df['genres'] != '(no genres listed)']\n",
     "movies_df = movies_df[movies_df['movieId'].isin(movies_with_genome)]\n",
     "\n",
     "all_movie_ids = movies_df['movieId'].unique()\n",
     "\n",
     "ratings_df = pd.read_csv(ratings)\n",
     "ratings_df = ratings_df[ratings_df['movieId'].isin(all_movie_ids)]\n",
     "ratings_df = ratings_df.loc[:, ['userId', 'movieId', 'rating']]\n",
     "\n",
     "all_user_ids = ratings_df['userId'].unique()\n",
     "\n",
     "# ratings_df\n",
     "# %%\n",
     "# TODO also filter users only inside recommendations or answers dataframe\n",
     "count_df = answers_df.groupby('userId').count()\n",
     "# count_df[count_df['movieId'] == 5]\n",
     "all_answers_user_ids = count_df[count_df['movieId'] == 5].index.values\n",
     "# %%\n",
     "# 140928\n",
     "# np.where(all_answers_user_ids == 140928)\n",
     "# all_answers_user_ids[194]\n",
     "\n",
     "# self.movie_movie_distances.loc[\n",
     "#             candidate_movie_id, users_all_ratings_df['movieId']].values[0]\n",
     "\n",
     "# ratings_df[ratings_df['userId'] == 140928]\n",
     "# %%\n",
     "from sklearn.metrics import pairwise_distances, mean_absolute_error, mean_squared_error\n",
     "\n",
     "\n",
     "class ContentBased_Recommender:\n",
     "    def __init__(self, term_vector_df, ratings_df, K=5, metric='cosine', weighted=True):\n",
     "        self.term_vector_df = term_vector_df\n",
     "        self.K = K\n",
     "        self.ratings_df = ratings_df\n",
     "        self.weighted = weighted\n",
     "\n",
     "        # preprocessing and other calculations\n",
     "        self.term_vector_df.fillna(0, inplace=True)\n",
     "        self.movie_movie_distances = pd.DataFrame(\n",
     "            pairwise_distances(self.term_vector_df, metric=metric), index=self.term_vector_df.index,\n",
     "            columns=self.term_vector_df.index)\n",
     "\n",
     "    def get_mae_mse(self, user_id, candidate_movie_id, user_movies):\n",
     "        # movies watched by user\n",
     "        #         if user_movies is None:\n",
     "        #             user_movies = ratings_df[ratings_df['userId'] == user_id]['movieId'].values\n",
     "\n",
     "        # hide candidate movie from the user\n",
     "        user_movies = np.setdiff1d(user_movies, candidate_movie_id)\n",
     "\n",
     "        # load user rating for watched movies other than the candidate movie\n",
     "        # user_ratings =\n",
     "        users_all_ratings_df = ratings_df[ratings_df['userId'] == user_id]\n",
     "        users_all_ratings_df = users_all_ratings_df[\n",
     "            users_all_ratings_df['movieId'].isin(user_movies)]\n",
     "\n",
     "        # load similarities to the candidate movie\n",
     "        users_all_ratings_df['sim_candidate_movie'] = self.movie_movie_distances.loc[\n",
     "            candidate_movie_id, users_all_ratings_df['movieId']].values\n",
     "\n",
     "        mae, mse = self.predict_ratings_and_get_mae_mse(user_id, candidate_movie_id,\n",
     "                                                        users_all_ratings_df)\n",
     "\n",
     "        return mae, mse\n",
     "\n",
     "    def predict_ratings_and_get_mae_mse(self, user_id, candidate_movie_id, users_all_ratings_df):\n",
     "        user_ratings = users_all_ratings_df['rating'].values[:self.K]\n",
     "        similarities = users_all_ratings_df['sim_candidate_movie'].values[:self.K]\n",
     "\n",
     "        predicted_rating = 0\n",
     "        if self.weighted:\n",
     "            # weighted average\n",
     "            predicted_rating = np.sum(user_ratings * similarities) / np.sum(similarities)\n",
     "        else:\n",
     "            # non-weighted average\n",
     "            predicted_rating = np.sum(user_ratings) / len(user_ratings)\n",
     "\n",
     "        actual_rating = self.ratings_df[(self.ratings_df['userId'] == user_id) & (\n",
     "                self.ratings_df['movieId'] == candidate_movie_id)]['rating'].values[0]\n",
     "\n",
     "        if np.isnan(predicted_rating):\n",
     "            #             predicted_rating = 0\n",
     "            predicted_rating = actual_rating\n",
     "\n",
     "        mae = mean_absolute_error([actual_rating], [predicted_rating])\n",
     "        mse = mean_squared_error([actual_rating], [predicted_rating])\n",
     "\n",
     "        return mae, mse\n",
     "\n",
     "    def get_average_mae_mse(self, user_id, user_movies):\n",
     "        # movies watched by user\n",
     "        #         if user_movies is None:\n",
     "        #             user_movies = ratings_df[ratings_df['userId'] == user_id]['movieId'].values\n",
     "\n",
     "        mae_list = list()\n",
     "        mse_list = list()\n",
     "\n",
     "        for candidate_movie_id in user_movies:\n",
     "            mae, mse = self.get_mae_mse(user_id, candidate_movie_id, user_movies)\n",
     "\n",
     "            mae_list.append(mae)\n",
     "            mse_list.append(mse)\n",
     "\n",
     "        return np.median(np.array(mae_list)), np.median(np.array(mse_list))\n",
     "\n",
     "\n",
     "# %%\n",
     "l1 = 'movies_lemmatized_threshold_'\n",
     "l2 = '_float_movie_genomes_bz2'\n",
     "\n",
     "# threshold_0.2_float_movie_genomes_bz2\n",
     "l3 = 'threshold_'\n",
     "l4 = '_float_movie_genomes_bz2'\n",
     "thresholds = [0.25, 0.4, 0.7]\n",
     "\n",
     "lemmatized_labels = [(l1 + str(x) + l2) for x in thresholds]\n",
     "lemmatized_labels\n",
     "\n",
     "full_labels = [(l3 + str(x) + l4) for x in thresholds]\n",
     "full_labels\n",
     "# %%\n",
     "# loading all required data\n",
     "user_full_genome_terms_df = pd.read_pickle(output_dir + 'user_full_genome_terms_df_bz2',\n",
     "                                           compression='bz2')\n",
     "user_full_genome_terms_gzip_df = pd.read_pickle(output_dir + 'user_full_genome_terms_df_gzip',\n",
     "                                                compression='bz2')\n",
     "\n",
     "lemmatized_thresholded_dfs = list()\n",
     "full_thresholded_dfs = list()\n",
     "\n",
     "for i, t in enumerate(thresholds):\n",
     "    lemmatized_thresholded_dfs.append(\n",
     "        pd.read_pickle(output_dir + lemmatized_labels[i], compression='bz2'))\n",
     "    full_thresholded_dfs.append(\n",
     "        pd.read_pickle(output_dir + full_labels[i], compression='bz2'))\n",
     "# %%\n",
     "# load term vectors\n",
     "genre_binary_terms_df = pd.read_pickle(genre_binary_terms, compression='bz2')\n",
     "movies_lemmatized_df = pd.read_pickle(movies_lemmatized, compression='bz2')\n",
     "# %%\n",
     "import matplotlib.pyplot as plt\n",
     "from time import time\n",
     "import warnings\n",
     "\n",
     "warnings.filterwarnings('ignore')\n",
     "\n",
     "labels = ['genre_binary', 'genome_full', 'genome_lemmatized']\n",
     "all_movie_ids = genre_binary_terms_df.index.values\n",
     "\n",
     "\n",
     "def run(index, K, start_range, end_range):\n",
     "    #     for index, K in enumerate(K_ranges):\n",
     "    genre_recommender = ContentBased_Recommender(genre_binary_terms_df, ratings_df, K,\n",
     "                                                 metric='jaccard', weighted=True)\n",
     "    genome_full_recommender = ContentBased_Recommender(genome_scores_df, ratings_df, K,\n",
     "                                                       metric='cosine', weighted=True)\n",
     "    genome_lemmatized_recommender = ContentBased_Recommender(movies_lemmatized_df, ratings_df, K,\n",
     "                                                             metric='cosine', weighted=True)\n",
     "\n",
     "    lemmatized_recommenders = list()\n",
     "    full_recommenders = list()\n",
     "\n",
     "    for i, t in enumerate(thresholds):\n",
     "        full_recommenders.append(\n",
     "            ContentBased_Recommender(full_thresholded_dfs[i], ratings_df, K, weighted=True))\n",
     "        lemmatized_recommenders.append(\n",
     "            ContentBased_Recommender(lemmatized_thresholded_dfs[i], ratings_df, K, weighted=True))\n",
     "\n",
     "    # mae lists\n",
     "    genre_mae_list = list()\n",
     "    genome_full_mae_list = list()\n",
     "    genome_lemmatized_mae_list = list()\n",
     "\n",
     "    lemmatized_mae_list = list()\n",
     "    full_mae_list = list()\n",
     "\n",
     "    # mse lists\n",
     "    genre_mse_list = list()\n",
     "    genome_full_mse_list = list()\n",
     "    genome_lemmatized_mse_list = list()\n",
     "\n",
     "    lemmatized_mse_list = list()\n",
     "    full_mse_list = list()\n",
     "\n",
     "    for user_id in all_answers_user_ids[start_range:end_range]:\n",
     "        start_time = time()\n",
     "        print('user_id', user_id)\n",
     "\n",
     "        # movies watched by user\n",
     "        user_movies = ratings_df[ratings_df['userId'] == user_id]['movieId'].values\n",
     "\n",
     "        if len(user_movies) <= 1:\n",
     "            continue\n",
     "\n",
     "        mae, mse = genre_recommender.get_average_mae_mse(user_id, user_movies)\n",
     "        genre_mae_list.append(mae)\n",
     "        genre_mse_list.append(mse)\n",
     "\n",
     "        mae, mse = genome_full_recommender.get_average_mae_mse(user_id, user_movies)\n",
     "        genome_full_mae_list.append(mae)\n",
     "        genome_full_mse_list.append(mse)\n",
     "\n",
     "        mae, mse = genome_lemmatized_recommender.get_average_mae_mse(user_id, user_movies)\n",
     "        genome_lemmatized_mae_list.append(mae)\n",
     "        genome_lemmatized_mse_list.append(mse)\n",
     "\n",
     "        for i, t in enumerate(thresholds):\n",
     "            mae, mse = full_recommenders[i].get_average_mae_mse(user_id, user_movies)\n",
     "            full_mae_list.append(mae)\n",
     "            full_mse_list.append(mse)\n",
     "\n",
     "            mae, mse = lemmatized_recommenders[i].get_average_mae_mse(user_id, user_movies)\n",
     "            lemmatized_mae_list.append(mae)\n",
     "            lemmatized_mse_list.append(mse)\n",
     "\n",
     "        finish_time = time() - start_time\n",
     "        print(\"Total time taken for this user: %f seconds\" % finish_time)\n",
     "\n",
     "    mae_df = pd.DataFrame()\n",
     "    mae_df['genre_MAE'] = genre_mae_list\n",
     "    mae_df['genome_full_MAE'] = genome_full_mae_list\n",
     "    mae_df['genome_lemmatized_MAE'] = genome_lemmatized_mae_list\n",
     "\n",
     "    mse_df = pd.DataFrame()\n",
     "    mse_df['genre_MSE'] = genre_mse_list\n",
     "    mse_df['genome_full_MSE'] = genome_full_mse_list\n",
     "    mse_df['genome_lemmatized_MSE'] = genome_lemmatized_mse_list\n",
     "\n",
     "    for i, t in enumerate(thresholds):\n",
     "        mae_df[full_labels[i] + '_MAE'] = full_mae_list[i]\n",
     "        mse_df[full_labels[i] + '_MSE'] = full_mse_list[i]\n",
     "\n",
     "        mae_df[lemmatized_labels[i] + '_MAE'] = lemmatized_mae_list[i]\n",
     "        mse_df[lemmatized_labels[i] + '_MSE'] = lemmatized_mse_list[i]\n",
     "\n",
     "    print(\"\")\n",
     "    mae_df.median().plot(kind='barh',\n",
     "                         title='K=' + str(K) + ', avg MAE across all users, for all movies')\n",
     "    plt.show()\n",
     "    mse_df.median().plot(kind='barh',\n",
     "                         title='K=' + str(K) + ', avg MSE across all users, for all movies')\n",
     "    plt.show()\n",
     "\n",
     "\n",
     "import multiprocessing as mp\n",
     "import matplotlib.pyplot as plt\n",
     "\n",
     "# K_ranges = [5, 10, 15, 20, 30, 40, 50]\n",
     "# K_ranges = [5, 10, 15, 20]\n",
     "K_ranges = [5]\n",
     "start_range = 0\n",
     "end_range = 5\n",
     "\n",
     "p_list = list()\n",
     "for index, K in enumerate(K_ranges):\n",
     "    p = mp.Process(target=run, args=(index, K,start_range, end_range,))\n",
     "    p_list.append(p)\n",
     "    p.start()\n",
     "\n",
     "for p in p_list:\n",
     "    # wait until all processes are finished\n",
     "    p.join()\n",
     "\n",
     "print(\"main process\")\n"
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
